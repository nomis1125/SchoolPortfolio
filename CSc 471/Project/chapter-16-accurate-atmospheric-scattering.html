<!doctype html>
<html lang="en" dir="ltr"
  xmlns:og="http://ogp.me/ns#"
  xmlns:article="http://ogp.me/ns/article#"
  xmlns:book="http://ogp.me/ns/book#"
  xmlns:profile="http://ogp.me/ns/profile#"
  xmlns:video="http://ogp.me/ns/video#"
  xmlns:product="http://ogp.me/ns/product#">
<head profile="http://www.w3.org/1999/xhtml/vocab">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta charset="utf-8"><script type="text/javascript">(window.NREUM||(NREUM={})).loader_config={licenseKey:"6f2048d7bc",applicationID:"341156206"};window.NREUM||(NREUM={}),__nr_require=function(e,n,t){function r(t){if(!n[t]){var i=n[t]={exports:{}};e[t][0].call(i.exports,function(n){var i=e[t][1][n];return r(i||n)},i,i.exports)}return n[t].exports}if("function"==typeof __nr_require)return __nr_require;for(var i=0;i<t.length;i++)r(t[i]);return r}({1:[function(e,n,t){function r(){}function i(e,n,t){return function(){return o(e,[u.now()].concat(f(arguments)),n?null:this,t),n?void 0:this}}var o=e("handle"),a=e(4),f=e(5),c=e("ee").get("tracer"),u=e("loader"),s=NREUM;"undefined"==typeof window.newrelic&&(newrelic=s);var p=["setPageViewName","setCustomAttribute","setErrorHandler","finished","addToTrace","inlineHit","addRelease"],l="api-",d=l+"ixn-";a(p,function(e,n){s[n]=i(l+n,!0,"api")}),s.addPageAction=i(l+"addPageAction",!0),s.setCurrentRouteName=i(l+"routeName",!0),n.exports=newrelic,s.interaction=function(){return(new r).get()};var m=r.prototype={createTracer:function(e,n){var t={},r=this,i="function"==typeof n;return o(d+"tracer",[u.now(),e,t],r),function(){if(c.emit((i?"":"no-")+"fn-start",[u.now(),r,i],t),i)try{return n.apply(this,arguments)}catch(e){throw c.emit("fn-err",[arguments,this,e],t),e}finally{c.emit("fn-end",[u.now()],t)}}}};a("actionText,setName,setAttribute,save,ignore,onEnd,getContext,end,get".split(","),function(e,n){m[n]=i(d+n)}),newrelic.noticeError=function(e,n){"string"==typeof e&&(e=new Error(e)),o("err",[e,u.now(),!1,n])}},{}],2:[function(e,n,t){function r(e,n){var t=e.getEntries();t.forEach(function(e){"first-paint"===e.name?c("timing",["fp",Math.floor(e.startTime)]):"first-contentful-paint"===e.name&&c("timing",["fcp",Math.floor(e.startTime)])})}function i(e,n){var t=e.getEntries();t.length>0&&c("lcp",[t[t.length-1]])}function o(e){if(e instanceof s&&!l){var n,t=Math.round(e.timeStamp);n=t>1e12?Date.now()-t:u.now()-t,l=!0,c("timing",["fi",t,{type:e.type,fid:n}])}}if(!("init"in NREUM&&"page_view_timing"in NREUM.init&&"enabled"in NREUM.init.page_view_timing&&NREUM.init.page_view_timing.enabled===!1)){var a,f,c=e("handle"),u=e("loader"),s=NREUM.o.EV;if("PerformanceObserver"in window&&"function"==typeof window.PerformanceObserver){a=new PerformanceObserver(r),f=new PerformanceObserver(i);try{a.observe({entryTypes:["paint"]}),f.observe({entryTypes:["largest-contentful-paint"]})}catch(p){}}if("addEventListener"in document){var l=!1,d=["click","keydown","mousedown","pointerdown","touchstart"];d.forEach(function(e){document.addEventListener(e,o,!1)})}}},{}],3:[function(e,n,t){function r(e,n){if(!i)return!1;if(e!==i)return!1;if(!n)return!0;if(!o)return!1;for(var t=o.split("."),r=n.split("."),a=0;a<r.length;a++)if(r[a]!==t[a])return!1;return!0}var i=null,o=null,a=/Version\/(\S+)\s+Safari/;if(navigator.userAgent){var f=navigator.userAgent,c=f.match(a);c&&f.indexOf("Chrome")===-1&&f.indexOf("Chromium")===-1&&(i="Safari",o=c[1])}n.exports={agent:i,version:o,match:r}},{}],4:[function(e,n,t){function r(e,n){var t=[],r="",o=0;for(r in e)i.call(e,r)&&(t[o]=n(r,e[r]),o+=1);return t}var i=Object.prototype.hasOwnProperty;n.exports=r},{}],5:[function(e,n,t){function r(e,n,t){n||(n=0),"undefined"==typeof t&&(t=e?e.length:0);for(var r=-1,i=t-n||0,o=Array(i<0?0:i);++r<i;)o[r]=e[n+r];return o}n.exports=r},{}],6:[function(e,n,t){n.exports={exists:"undefined"!=typeof window.performance&&window.performance.timing&&"undefined"!=typeof window.performance.timing.navigationStart}},{}],ee:[function(e,n,t){function r(){}function i(e){function n(e){return e&&e instanceof r?e:e?c(e,f,o):o()}function t(t,r,i,o){if(!l.aborted||o){e&&e(t,r,i);for(var a=n(i),f=v(t),c=f.length,u=0;u<c;u++)f[u].apply(a,r);var p=s[y[t]];return p&&p.push([b,t,r,a]),a}}function d(e,n){h[e]=v(e).concat(n)}function m(e,n){var t=h[e];if(t)for(var r=0;r<t.length;r++)t[r]===n&&t.splice(r,1)}function v(e){return h[e]||[]}function g(e){return p[e]=p[e]||i(t)}function w(e,n){u(e,function(e,t){n=n||"feature",y[t]=n,n in s||(s[n]=[])})}var h={},y={},b={on:d,addEventListener:d,removeEventListener:m,emit:t,get:g,listeners:v,context:n,buffer:w,abort:a,aborted:!1};return b}function o(){return new r}function a(){(s.api||s.feature)&&(l.aborted=!0,s=l.backlog={})}var f="nr@context",c=e("gos"),u=e(4),s={},p={},l=n.exports=i();l.backlog=s},{}],gos:[function(e,n,t){function r(e,n,t){if(i.call(e,n))return e[n];var r=t();if(Object.defineProperty&&Object.keys)try{return Object.defineProperty(e,n,{value:r,writable:!0,enumerable:!1}),r}catch(o){}return e[n]=r,r}var i=Object.prototype.hasOwnProperty;n.exports=r},{}],handle:[function(e,n,t){function r(e,n,t,r){i.buffer([e],r),i.emit(e,n,t)}var i=e("ee").get("handle");n.exports=r,r.ee=i},{}],id:[function(e,n,t){function r(e){var n=typeof e;return!e||"object"!==n&&"function"!==n?-1:e===window?0:a(e,o,function(){return i++})}var i=1,o="nr@id",a=e("gos");n.exports=r},{}],loader:[function(e,n,t){function r(){if(!x++){var e=E.info=NREUM.info,n=d.getElementsByTagName("script")[0];if(setTimeout(s.abort,3e4),!(e&&e.licenseKey&&e.applicationID&&n))return s.abort();u(y,function(n,t){e[n]||(e[n]=t)}),c("mark",["onload",a()+E.offset],null,"api");var t=d.createElement("script");t.src="https://"+e.agent,n.parentNode.insertBefore(t,n)}}function i(){"complete"===d.readyState&&o()}function o(){c("mark",["domContent",a()+E.offset],null,"api")}function a(){return O.exists&&performance.now?Math.round(performance.now()):(f=Math.max((new Date).getTime(),f))-E.offset}var f=(new Date).getTime(),c=e("handle"),u=e(4),s=e("ee"),p=e(3),l=window,d=l.document,m="addEventListener",v="attachEvent",g=l.XMLHttpRequest,w=g&&g.prototype;NREUM.o={ST:setTimeout,SI:l.setImmediate,CT:clearTimeout,XHR:g,REQ:l.Request,EV:l.Event,PR:l.Promise,MO:l.MutationObserver};var h=""+location,y={beacon:"bam.nr-data.net",errorBeacon:"bam.nr-data.net",agent:"js-agent.newrelic.com/nr-1167.min.js"},b=g&&w&&w[m]&&!/CriOS/.test(navigator.userAgent),E=n.exports={offset:f,now:a,origin:h,features:{},xhrWrappable:b,userAgent:p};e(1),e(2),d[m]?(d[m]("DOMContentLoaded",o,!1),l[m]("load",r,!1)):(d[v]("onreadystatechange",i),l[v]("onload",r)),c("mark",["firstbyte",f],null,"api");var x=0,O=e(6)},{}],"wrap-function":[function(e,n,t){function r(e){return!(e&&e instanceof Function&&e.apply&&!e[a])}var i=e("ee"),o=e(5),a="nr@original",f=Object.prototype.hasOwnProperty,c=!1;n.exports=function(e,n){function t(e,n,t,i){function nrWrapper(){var r,a,f,c;try{a=this,r=o(arguments),f="function"==typeof t?t(r,a):t||{}}catch(u){l([u,"",[r,a,i],f])}s(n+"start",[r,a,i],f);try{return c=e.apply(a,r)}catch(p){throw s(n+"err",[r,a,p],f),p}finally{s(n+"end",[r,a,c],f)}}return r(e)?e:(n||(n=""),nrWrapper[a]=e,p(e,nrWrapper),nrWrapper)}function u(e,n,i,o){i||(i="");var a,f,c,u="-"===i.charAt(0);for(c=0;c<n.length;c++)f=n[c],a=e[f],r(a)||(e[f]=t(a,u?f+i:i,o,f))}function s(t,r,i){if(!c||n){var o=c;c=!0;try{e.emit(t,r,i,n)}catch(a){l([a,t,r,i])}c=o}}function p(e,n){if(Object.defineProperty&&Object.keys)try{var t=Object.keys(e);return t.forEach(function(t){Object.defineProperty(n,t,{get:function(){return e[t]},set:function(n){return e[t]=n,n}})}),n}catch(r){l([r])}for(var i in e)f.call(e,i)&&(n[i]=e[i]);return n}function l(n){try{e.emit("internal-error",n)}catch(t){}}return e||(e=i),t.inPlace=u,t.flag=a,t}},{}]},{},["loader"]);</script>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<script src="https://cdn.auth0.com/js/auth0/9.5.1/auth0.min.js"></script>
<script src="https://developer.nvidia.com/register/dz-auth.js?v=3.2.5c"></script>
<link rel="shortcut icon" href="https://developer.nvidia.com/sites/all/themes/devzone_base/favicon.ico" type="image/vnd.microsoft.icon" />
<link rel="alternate" type="application/rss+xml" title="RSS - Chapter 16. Accurate Atmospheric Scattering" href="https://developer.nvidia.com/taxonomy/term/1372/feed" />
<meta name="description" content="Chapter 16. Accurate Atmospheric Scattering  Sean O&#039;Neil  16.1 Introduction  Generating realistic atmospheric scattering for computer graphics has always been a difficult problem, but it is very important for rendering realistic outdoor environments. The equations that describe atmospheric scattering are so complex  that entire books have been dedicated to the subject." />
<meta name="generator" content="Drupal 7 (http://drupal.org)" />
<link rel="canonical" href="https://developer.nvidia.com/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-16-accurate-atmospheric-scattering" />
<link rel="shortlink" href="https://developer.nvidia.com/taxonomy/term/1372" />
<meta property="og:site_name" content="NVIDIA Developer" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://developer.nvidia.com/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-16-accurate-atmospheric-scattering" />
<meta property="og:title" content="Chapter 16. Accurate Atmospheric Scattering" />
<meta property="og:description" content="Chapter 16. Accurate Atmospheric Scattering  Sean O&#039;Neil  16.1 Introduction  Generating realistic atmospheric scattering for computer graphics has always been a difficult problem, but it is very important for rendering realistic outdoor environments. The equations that describe atmospheric scattering are so complex  that entire books have been dedicated to the subject. Computer graphics models generally use simplified equations, and very few of them run at interactive frame rates. This chapter explains how to implement a real-time atmospheric scattering  algorithm entirely on the GPU using the methods described in Nishita et al. 1993. Figure 16-1 shows screenshots from the scattering demo included on this book&#039;s CD.       Figure 16-1 Screenshots from the Scattering Demo    Many atmospheric scattering models assume that the camera is always on or very close to the ground. This makes it easier to assume that the atmosphere has a constant density at all altitudes, which simplifies the scattering equations in  Nishita et al. 1993 tremendously. Refer to Hoffman and Preetham 2002 for an explanation of how to implement these simplified equations in a GPU shader. This implementation produces an attractive scattering effect that is very fast on DirectX  8.0 shaders. Unfortunately, it doesn&#039;t always produce very accurate results, and it doesn&#039;t work well for a flight or space simulator, in which the camera can be located in space or very high above the ground.  This chapter explains how to implement the full equations from Nishita et al. 1993 in a GPU shader that runs at interactive frame rates. These equations model the atmosphere more accurately, with density falling off exponentially as  altitude increases. O&#039;Neil 2004 describes a similar algorithm that ran on the CPU, but that algorithm was too CPU-intensive. It was based on a precalculated 2D lookup table with four floating-point channels. Calculating the color for each  vertex required several lookups into the table, with extra calculations around each lookup. At the time that article was written, no GPU could support such operations in a shader in one pass.  In this chapter, we eliminate the lookup table without sacrificing image quality, allowing us to implement the entire algorithm in a GPU shader. These shaders are small and fast enough to run in real time on most GPUs that support DirectX  Shader Model 2.0.  16.2 Solving the Scattering Equations  The scattering equations have nested integrals that are impossible to solve analytically; fortunately, it&#039;s easy to numerically compute the value of an integral with techniques such as the trapezoid rule. Approximating an integral in this  manner boils down to a weighted sum calculated in a loop. Imagine a line segment on a graph: break up the segment into n sample segments and evaluate the integrand at the center point of each sample segment. Multiply each result by  the length of the sample segment and add them all up. Taking more samples makes the result more accurate, but it also makes the integral more expensive to calculate.  In our case, the line segment is a ray from the camera through the atmosphere to a vertex. This vertex can be part of the terrain, part of the sky dome, part of a cloud, or even part of an object in space such as the moon. If the ray passes  through the atmosphere to get to the vertex, scattering needs to be calculated. Every ray should have two points defined that mark where the ray starts passing through the atmosphere and where it stops passing through the atmosphere. We&#039;ll  call these points A and B, and they are shown in Figure 16-2. When the camera is inside the atmosphere, A is the camera&#039;s position. When the vertex is inside the atmosphere, B is the vertex&#039;s position. When  either point is in space, we perform a sphere-intersection check to find out where the ray intersects the outer atmosphere, and then we make the intersection point A or B.       Figure 16-2 The Geometry of Atmospheric Scattering    Now we have a line segment defined from point A to point B, and we want to approximate the integral that describes the atmospheric scattering across its length. For now let&#039;s take five sample positions and name their  points P 1 through P 5. Each point P 1 through P 5 represents a point in the atmosphere at which light scatters; light comes into the atmosphere from the sun,  scatters at that point, and is reflected toward the camera. Consider the point P 5, for example. Sunlight goes directly from the sun to P 5 in a straight line. Along that line the atmosphere scatters  some of the light away from P 5. At P 5, some of this light is scattered directly toward the camera. As the light from P 5 travels to the camera, some of it gets scattered away  again.  16.2.1 Rayleigh Scattering vs. Mie Scattering  Another important detail is related to how the light scattering at the point P is modeled. Different particles in the atmosphere scatter light in different ways. The two most common forms of scattering in the atmosphere are  Rayleigh scattering and Mie scattering. Rayleigh scattering is caused by small molecules in the air, and it scatters light more heavily at the shorter wavelengths (blue first, then green, and then red). The sky is  blue because the blue light bounces all over the place, and ultimately reaches your eyes from every direction. The sun&#039;s light turns yellow/orange/red at sunset because as light travels far through the atmosphere, almost all of the blue and  much of the green light is scattered away before it reaches you, leaving just the reddish colors.  Mie scattering is caused by larger particles in the air called aerosols (such as dust and pollution), and it tends to scatter all wavelengths of light equally. On a hazy day, Mie scattering causes the sky to look a bit gray and causes the  sun to have a large white halo around it. Mie scattering can also be used to simulate light scattered from small particles of water and ice in the air, to produce effects like rainbows, but that is beyond the scope of this chapter. (Refer to  Brewer 2004 for more information.)  16.2.2 The Phase Function    The phase function describes how much light is scattered toward the direction of the camera based on the angle (the angle between the two green rays in Figure 16-2) and a constant g that  affects the symmetry of the scattering. There are many different versions of the phase function. This one is an adaptation of the Henyey-Greenstein function used in Nishita et al. 1993.  Rayleigh scattering can be approximated by setting g to 0, which greatly simplifies the equation and makes it symmetrical for positive and negative angles. Negative values of g scatter more light in a forward direction,  and positive values of g scatter more light back toward the light source. For Mie aerosol scattering, g is usually set between -0.75 and -0.999. Never set g to 1 or -1, as it makes the equation reduce to 0.  16.2.3 The Out-Scattering Equation    The out-scattering equation is the inner integral mentioned earlier. The integral part determines the &quot;optical depth,&quot; or the average atmospheric density across the ray from point Pa to point Pb  multiplied by the length of the ray. This is also called the &quot;optical length&quot; or &quot;optical thickness.&quot; Think of it as a weighting factor based on how many air particles are in the path of the light along the ray. The rest of the equation is  made up of constants, and they determine how much of the light those particles scatter away from the ray.  To compute the value of this integral, the ray from Pa to Pb will be broken up into segments and the exponential term will be evaluated at each sample point. The variable h is the height of  the sample point. In my implementation, the height is scaled so that 0 represents sea level and 1 is at the top of the atmosphere. In theory, the atmosphere has no fixed top, but for practical purposes, we have to choose some height at which  to render the sky dome. H 0 is the scale height, which is the height at which the atmosphere&#039;s average density is found. My implementation uses 0.25, so the average density is found 25 percent of the way up from the ground  to the sky dome.  The constant is the wavelength (or color) of light and K() is the scattering constant, which is dependent on the density of the atmosphere at sea level. Rayleigh and Mie  scattering each have their own scattering constants, including the scale height (H 0). Rayleigh and Mie scattering also differ in how they depend on wavelength. The Rayleigh scattering constant is usually divided by  4. In most computer graphics models, the Mie scattering constant is not dependent on wavelength, but at least one implementation divides it by 0.84. Wherever this  equation depends on wavelength, it must be solved separately for each of the three color channels and separately for each type of scattering.  16.2.4 The In-Scattering Equation    The in-scattering equation describes how much light is added to a ray through the atmosphere due to light scattering from the sun. For each point P along the ray from Pa to Pb ,  PPc is the ray from the point to the sun and PPa is the ray from the sample point to the camera. The out-scattering function determines how much light is scattered away along the two green rays in Figure 16-2. The  remaining light is scaled by the phase function, the scattering constant, and the intensity of the sunlight, Is (). The sunlight intensity does not have to be dependent on wavelength, but this is  where you would apply the color if you wanted to create an alien world revolving around a purple star.  16.2.5 The Surface-Scattering Equation              I&#039;v () = Iv () + I e() x exp (â€“t (Pa Pb ,    ))            To scatter light reflected from a surface, such as the surface of a planet, you must take into account the fact that some of the reflected light will be scattered away on its way to the camera. In addition, extra light is scattered in from  the atmosphere. Ie () is the amount of light emitted or reflected from a surface, and it is attenuated by an out-scattering factor. The sky is not a surface that can reflect or emit light, so  only Iv () is needed to render the sky. Determining how much light is reflected or emitted by a surface is application-specific, but for reflected sunlight, you need to account for the  out-scattering that takes place before the sunlight strikes the surface (that is, Is () x exp(-t(Pc Pb ,))), and use that as  the color of the light when determining how much light the surface reflects.  16.3 Making It Real-Time  Let&#039;s find out how poorly these equations will perform if they&#039;re implemented as explained in the preceding section, with five sample points for the in-scattering equation and five sample points for each of the integrals to compute the  out-scattering equations. This gives 5 x (5 + 5) samples at which to evaluate the functions for each vertex. We also have two types of scattering, Rayleigh and Mie, and we have to calculate each one for the different wavelengths of each of the  three color channels (RGB). So now we&#039;re up to approximately 2 x 3 x 5 x (5 + 5), or 300 computations per vertex. To make matters worse, the visual quality suffers noticeably when using only five samples for each integral. O&#039;Neil 2004 used 50  samples for the inner integrals and five for the outer integral, which pushes the number of calculations up to 3,000 per vertex!  We don&#039;t need to go any further to know that this will not run very fast. Nishita et al. 1993 used a precalculated 2D lookup table to cut the number of calculations in half, but it still won&#039;t run in real time. Their lookup table took  advantage of the fact that the sun is so far away that its rays can be considered parallel. (This idea is reflected in the in-scattering equation, in Section 16.2.4.) This makes it possible to calculate a lookup table that contains the amount  of out-scattering for rays going from the sun to any point in the atmosphere. This table replaces one of the out-scattering integrals with a lookup table whose variables are altitude and angle to the sun. Because the rays to the camera are not  parallel, the out-scattering integral for camera rays still had to be solved at runtime.  In O&#039;Neil 2004, I proposed a better 2D lookup table that allows us to avoid both out-scattering integrals. The first dimension, x, takes a sample point at a specific altitude above the planet, with 0.0 being on the ground and 1.0  being at the top of the atmosphere. The second dimension, y, represents a vertical angle, with 0.0 being straight up and 1.0 being straight down. At each (x, y) pair in the table, a ray is fired from a point at  altitude x to the top of the atmosphere along angle y. The lookup table had four channels, two reserved for Rayleigh scattering and two reserved for Mie scattering. One channel for each simply contained the atmospheric  density at that altitude, or exp(-h/H 0). The other channel contained the optical depth of the ray just described. Because the lookup table was precomputed, I chose to use 50 samples to approximate the optical  depth integral, resulting in very good accuracy.  As with the lookup table proposed in Nishita et al. 1993, we can get the optical depth for the ray to the sun from any sample point in the atmosphere. All we need is the height of the sample point (x) and the angle from vertical to  the sun (y), and we look up (x, y) in the table. This eliminates the need to calculate one of the out-scattering integrals. In addition, the optical depth for the ray to the camera can be figured out in the same way,  right? Well, almost. It works the same way when the camera is in space, but not when the camera is in the atmosphere. That&#039;s because the sample rays used in the lookup table go from some point at height x all the way to the top of the  atmosphere. They don&#039;t stop at some point in the middle of the atmosphere, as they would need to when the camera is inside the atmosphere.  Fortunately, the solution to this is very simple. First we do a lookup from sample point P to the camera to get the optical depth of the ray passing through the camera to the top of the atmosphere. Then we do a second lookup for  the same ray, but starting at the camera instead of starting at P. This will give us the optical depth for the part of the ray that we don&#039;t want, and we can subtract it from the result of the first lookup. Examine the rays starting  from the ground vertex (B 1) in Figure 16-3 for a graphical representation of this.       Figure 16-3Problems with the Improved Lookup Table    There&#039;s only one problem left. When a vertex is above the camera in the atmosphere, the ray from sample point P through the camera can pass through the planet itself. The height variable is not expected to go so far negative, and  it can cause the numbers in the lookup table to go extremely high, losing precision and sometimes even encountering a floating-point overflow. The way to avoid this problem is to reverse the direction of the rays when the vertex is above the  camera. Examine the rays passing through the sky vertex (B 2) in Figure 16-3 for a graphical representation of this.  So now we&#039;ve reduced 3,000 calculations per vertex to something closer to 2 x 3 x 5 x (1 + 1), or 60 (assuming five samples for the out-scattering integral for the eye ray). Implemented in software on an Athlon 2500+ with an inefficient  brute-force rendering method, I was able to get this method to run between 50 and 100 frames per second.  16.4 Squeezing It into a Shader  At this point, I felt that this algorithm had been squeezed about as much as it could, but I knew that I had to squeeze it even smaller to fit it into a shader. I didn&#039;t want this algorithm to require Shader Model 3.0, so having lookup  tables in textures used by the vertex shaders wasn&#039;t possible. I decided to take a different approach and started to mathematically analyze the results of the lookup table. Even though I knew I couldn&#039;t come up with a way to simplify the  integral equations, I had hoped that I might be able to simulate the results closely enough with a completely different equation.  16.4.1 Eliminating One Dimension  I started by plotting the results of the lookup table on a graph. I plotted height from 0.0 to 1.0 along the x axis and the lookup table result (optical depth) along the y axis. For various angles sampled from 0 to 1, I  plotted a separate line on the graph. I noticed right away that each line dropped off exponentially as x went from 0 to 1, but the scale of each line on the graph varied dramatically. This makes sense, because as the angle of the ray  goes from straight up to straight down, the length of the ray increases dramatically.  To make it easier to compare the shapes of the curves of each line, I decided to normalize them. I took the optical depth value at x = 0 (or height = 0) for each line and divided all of the values on that line by that value. This  scaled all lines on the graph to start at (x = 0, y = 1) and work their way down toward (x = 1, y = 0). To my surprise, almost all of the normalized lines fell right on top of each other on the graph! The  curve was almost exactly the same for every one, and that curve turned out to be exp(-4x).  This makes some sense, because the optical depth equation is the integral of exp(-h/H 0). I chose H 0 to be 0.25, so exp(-4h) is a common factor. It is still a bit puzzling, however,  as the h inside the integral is not the same as the height x outside the integral, which is only the height at the start of the ray. The h value inside the integral does not vary linearly, and it has more to do with  how it passes through a spherical space than with the starting height. There is some variation in the lines, and the variation increases as the angle increases. The variation gets worse exponentially as the angle increases over 90 degrees.  Because we don&#039;t care about angles that are much larger than 90 degrees (because the ray passes through the planet), exp(-4x) works very well for eliminating the x axis of the lookup table.  16.4.2 Eliminating the Other Dimension  Now that the x dimension (height) of the lookup table is being handled by exp(-4x), we need to eliminate the y dimension (angle). The only part of the optical depth that is not handled by exp(-4x) is the  scale used to normalize the lines on the graph explained previously, which is the value of the optical depth at x = 0. So now we create a new graph by plotting the angle from 0 to 1 on the x axis and the scale of each angle  on the y axis. For lack of a better name, I call this the scale function.  The first time I looked at the scale function, I noticed that it started at 0.25 (the scale height) and increased on some sort of accelerating curve. Thinking that it might be exponential, I divided the scales by the scale height (to make  the graph start at 1) and took the natural logarithm of the result. The result was another accelerating curve that I didn&#039;t recognize. I tried a number of curves, but nothing fit well on all parts of the curve. I ended up using graphical  analysis software to find a &quot;best fit&quot; equation for the curve, and it came back with a polynomial equation that was not pretty but fit the values well.  One significant drawback to this implementation is that the scale function is dependent on the scale height and the ratio between the atmosphere&#039;s thickness and the planet&#039;s radius. If either value changes, you need to calculate a new scale  function. In the demo included on this book&#039;s CD, the atmosphere&#039;s thickness (the distance from the ground to the top of the atmosphere) is 2.5 percent of the planet&#039;s radius, and the scale height is 25 percent of the atmosphere&#039;s thickness.  The radius of the planet doesn&#039;t matter as long as those two values stay the same.  16.5 Implementing the Scattering Shaders  Now that the problem has been solved mathematically, let&#039;s look at how the demo was implemented. The C++ code for the demo is fairly simple. The gluSphere() function is called to render both the ground and the sky dome. The front  faces are reversed for the sky dome so that the inside of its sphere is rendered. It uses a simple rectangular Earth texture to make it possible to see how the ground scattering affects colors on the ground, and it uses a simple glow texture  billboard to render the moon. No distinct sun is rendered, but the Mie scattering creates a glow in the sky dome that looks like the sun (only when seen through the atmosphere).  I have provided shader implementations in both Cg and GLSL on the book&#039;s CD. The ground, the sky, and objects in space each have two scattering shaders, one for when the camera is in space and one for when the camera is in the atmosphere  (this avoids conditional branching in the shaders). The ground shaders can be used for the terrain, as well as for objects that are beneath the camera. The sky shaders can be used for the sky dome, as well as for objects that are above the  camera. The space shaders can be used for any objects outside the atmosphere, such as the moon.  The naming convention for the shaders is &quot;render_object From camera_position&quot;. So the SkyFromSpace shader is used to render the sky dome when the camera is in space. There is also a common shader that contains some common  constants and helper functions used throughout the shaders. Let&#039;s use SkyFromSpace as an example.  16.5.1 The Vertex Shader  As you can see in Listing 16-1, SkyFromSpace.vert is a fairly complex vertex shader, but hopefully it&#039;s easy enough to follow with the comments in the code and the explanations provided here. Kr is the Rayleigh scattering constant,  Km is the Mie scattering constant, and ESun is the brightness of the sun. Rayleigh scatters different wavelengths of light at different rates, and the ratio is 1/pow(wavelength, 4). Referring back to Figure 16-2,  v3Start is point A from the previous examples and v3Start + fFar * v3Ray is point B. The variable v3SamplePoint goes from P 1 to Pn with each  iteration of the loop.  The variable fStartOffset is actually the value of the lookup table from point A going toward the camera. Why would we need to calculate this when it&#039;s at the outer edge of the atmosphere? Because the density is not truly  zero at the outer edge. The density falls off exponentially and it is close to zero, but if we do not calculate this value and use it as an offset, there may be a visible &quot;jump&quot; in color when the camera enters the atmosphere.  You may have noticed that the phase function is missing from this shader. The phase function depends on the angle toward the light source, and it suffers from tessellation artifacts if it is calculated per vertex. To avoid these artifacts,  the phase function is implemented in the fragment shader.  Example 16-1. SkyFromSpace.vert, Which Renders the Sky Dome When the Camera Is in Space  #include &quot;Common.cg&quot; vertout main(float4 gl_Vertex : POSITION, uniform float4x4 gl_ModelViewProjectionMatrix, uniform float3 v3CameraPos,  // The camera&#039;s current position  uniform float3 v3LightDir,  // Direction vector to the light source uniform float3 v3InvWavelength, // 1 / pow(wavelength, 4) for RGB uniform float fCameraHeight, // The camera&#039;s current height  uniform float fCameraHeight2, // fCameraHeight^2 uniform float fOuterRadius,  // The outer (atmosphere) radius uniform float fOuterRadius2, // fOuterRadius^2  uniform float fInnerRadius,  // The inner (planetary) radius uniform float fInnerRadius2, // fInnerRadius^2 uniform float fKrESun,   // Kr * ESun  uniform float fKmESun,   // Km * ESun uniform float fKr4PI,   // Kr * 4 * PI uniform float fKm4PI,   // Km * 4 * PI  uniform float fScale,   // 1 / (fOuterRadius - fInnerRadius) uniform float fScaleOverScaleDepth) // fScale / fScaleDepth { // Get the ray from the camera to the vertex and its length (which // is the far point of the ray passing through the atmosphere)  float3 v3Pos = gl_Vertex.xyz; float3 v3Ray = v3Pos - v3CameraPos; float fFar = length(v3Ray); v3Ray /= fFar;  // Calculate the closest intersection of the ray with // the outer atmosphere (point A in Figure 16-3)  float fNear = getNearIntersection(v3CameraPos, v3Ray, fCameraHeight2,          fOuterRadius2);  // Calculate the ray&#039;s start and end positions in the atmosphere, // then calculate its scattering offset float3 v3Start = v3CameraPos + v3Ray * fNear; fFar -= fNear; float fStartAngle = dot(v3Ray, v3Start) / fOuterRadius; float fStartDepth = exp(-fInvScaleDepth); float fStartOffset = fStartDepth * scale(fStartAngle);  // Initialize the scattering loop variables  float fSampleLength = fFar / fSamples; float fScaledLength = fSampleLength * fScale; float3 v3SampleRay = v3Ray * fSampleLength; float3 v3SamplePoint = v3Start + v3SampleRay * 0.5;  // Now loop through the sample points float3 v3FrontColor = float3(0.0, 0.0, 0.0); for(int i=0; i" />
  <title>Chapter 16. Accurate Atmospheric Scattering | NVIDIA Developer</title>
  <link type="text/css" rel="stylesheet" href="https://developer.nvidia.com/sites/default/files/css/css_lQaZfjVpwP_oGNqdtWCSpJT1EMqXdMiU84ekLLxQnc4.css" media="all" />
<link type="text/css" rel="stylesheet" href="https://developer.nvidia.com/sites/default/files/css/css_1ZLG5XSYPcVLpQGQXOlWMfoXSP1HeYJsmiGNX9R-bNM.css" media="all" />
<link type="text/css" rel="stylesheet" href="https://developer.nvidia.com/sites/default/files/css/css_VWGhZkkR4B4tMJA7PC_wov8dAxaI-MS03BCM3K8jjJA.css" media="screen" />
<link type="text/css" rel="stylesheet" href="https://developer.nvidia.com/sites/default/files/css/css_dDInFmDfqK3xzE6xbY2x7CyR2nlLxtXmEsFMHKgv2LI.css" media="all" />
<link type="text/css" rel="stylesheet" href="https://developer.nvidia.com/sites/default/files/css/css_QRimMrZK-Qv-u5bY8suH0j8mDYtzTPrd8f5XrKM55DE.css" media="all" />
<link type="text/css" rel="stylesheet" href="https://developer.nvidia.com/register/dz-auth.css?v=3.2.5c" media="all" />
<link type="text/css" rel="stylesheet" href="https://developer.nvidia.com/sites/default/files/css/css_dxTC2SnbUQpi6ay7fqSk9MkxtE4JRKtOHqpCvu7mKNQ.css" media="all" />
<link type="text/css" rel="stylesheet" href="https://developer.nvidia.com/sites/default/files/css/css_bkFDul3DNLpuZDW60IhCTtuds6REW2a6VAtWyGxqXzE.css" media="all" />
  <!-- HTML5 element support for IE6-8 -->
  <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->
  <script src="https://developer.nvidia.com/sites/default/files/js/js_b3CE8FGnsqqQIkfcKCuPN4xwA2qS2ziveSO6I2YYajM.js"></script>
<script src="https://developer.nvidia.com/sites/default/files/js/js_TFgoV4bMFv2k2ZtlxcbvU8BuMY9O0nTfLnsIEc2FAnM.js"></script>
<script src="//assets.adobedtm.com/b92787824f2e0e9b68dc2e993f9bd995339fe417/satelliteLib-7ba51e58dc61bcb0e9311aadd02a0108ab24cc6c.js"></script>
<script src="https://developer.nvidia.com/sites/default/files/js/js_MD7xFmVcvlVLmR3Y11l2jjghtPHI8cw1D7zgd1Sm_34.js"></script>
<script src="https://developer.nvidia.com/sites/default/files/js/js_oRBVbrZV7FAqu356imAriqUbp3bcQkSf7vs-78D-bp8.js"></script>
<script src="https://developer.nvidia.com/sites/default/files/js/js_KqPrINZjZ0WYOAdizDh6pg92JHmZHhOQjFPw8U4ojsk.js"></script>
<script src="https://d3js.org/d3.v4.min.js"></script>
<script src="https://developer.nvidia.com/sites/default/files/js/js_71nLSYIQk_wSj27WXNDDTvuWih8cYxMgUl68eN2C6MU.js"></script>
<script>jQuery.extend(Drupal.settings, {"basePath":"\/","pathPrefix":"","ajaxPageState":{"theme":"devzone_base","theme_token":"-gHoyBj0Epa3Pe5FB-2Zq2kv-o1qPtDjN1wZ8qUmGGo","js":{"0":1,"1":1,"sites\/all\/themes\/bootstrap\/js\/bootstrap.js":1,"sites\/all\/modules\/custom\/nvidia_tokens\/js\/horizontal-charts-init.js":1,"sites\/all\/modules\/contrib\/jquery_update\/replace\/jquery\/1.10\/jquery.min.js":1,"misc\/jquery-extend-3.4.0.js":1,"misc\/jquery.once.js":1,"misc\/drupal.js":1,"sites\/all\/modules\/contrib\/jquery_update\/replace\/ui\/ui\/minified\/jquery.ui.core.min.js":1,"sites\/all\/modules\/contrib\/jquery_update\/replace\/ui\/ui\/minified\/jquery.ui.widget.min.js":1,"sites\/all\/modules\/contrib\/jquery_update\/replace\/ui\/ui\/minified\/jquery.ui.position.min.js":1,"sites\/all\/modules\/contrib\/jquery_update\/replace\/ui\/ui\/minified\/jquery.ui.menu.min.js":1,"sites\/all\/modules\/contrib\/jquery_update\/replace\/ui\/ui\/minified\/jquery.ui.autocomplete.min.js":1,"sites\/all\/modules\/contrib\/jquery_update\/replace\/ui\/ui\/minified\/jquery.ui.button.min.js":1,"sites\/all\/modules\/contrib\/jquery_update\/replace\/ui\/ui\/minified\/jquery.ui.mouse.min.js":1,"sites\/all\/modules\/contrib\/jquery_update\/replace\/ui\/ui\/minified\/jquery.ui.draggable.min.js":1,"sites\/all\/modules\/contrib\/jquery_update\/replace\/ui\/ui\/minified\/jquery.ui.resizable.min.js":1,"sites\/all\/modules\/contrib\/jquery_update\/replace\/ui\/ui\/minified\/jquery.ui.dialog.min.js":1,"\/\/assets.adobedtm.com\/b92787824f2e0e9b68dc2e993f9bd995339fe417\/satelliteLib-7ba51e58dc61bcb0e9311aadd02a0108ab24cc6c.js":1,"sites\/all\/modules\/contrib\/codefilter\/codefilter.js":1,"sites\/all\/modules\/contrib\/gss\/scripts\/autocomplete.js":1,"sites\/all\/modules\/custom\/nvidia_quick_survey\/nvidia_quick_survey.js":1,"sites\/all\/libraries\/colorbox\/jquery.colorbox-min.js":1,"sites\/all\/modules\/contrib\/colorbox\/js\/colorbox.js":1,"sites\/all\/modules\/contrib\/hint\/hint.js":1,"sites\/all\/themes\/devzone_base\/js\/jquery.migrate.min.js":1,"sites\/all\/themes\/devzone_base\/js\/jquery.isotope.js":1,"sites\/all\/themes\/devzone_base\/js\/jquery.sidr.js":1,"sites\/all\/themes\/devzone_base\/js\/application.js":1,"sites\/all\/themes\/devzone_base\/js\/attrchange.js":1,"sites\/all\/themes\/devzone_base\/js\/scripts.js":1,"sites\/all\/themes\/devzone_base\/js\/adroll.js":1,"sites\/all\/themes\/devzone_base\/bootstrap\/js\/affix.js":1,"sites\/all\/themes\/devzone_base\/bootstrap\/js\/alert.js":1,"sites\/all\/themes\/devzone_base\/bootstrap\/js\/button.js":1,"sites\/all\/themes\/devzone_base\/bootstrap\/js\/carousel.js":1,"sites\/all\/themes\/devzone_base\/bootstrap\/js\/collapse.js":1,"sites\/all\/themes\/devzone_base\/bootstrap\/js\/dropdown.js":1,"sites\/all\/themes\/devzone_base\/bootstrap\/js\/modal.js":1,"sites\/all\/themes\/devzone_base\/bootstrap\/js\/tooltip.js":1,"sites\/all\/themes\/devzone_base\/bootstrap\/js\/popover.js":1,"sites\/all\/themes\/devzone_base\/bootstrap\/js\/scrollspy.js":1,"sites\/all\/themes\/devzone_base\/bootstrap\/js\/tab.js":1,"sites\/all\/themes\/devzone_base\/bootstrap\/js\/transition.js":1,"https:\/\/d3js.org\/d3.v4.min.js":1,"sites\/all\/modules\/custom\/nvidia_tokens\/js\/visualize-d.js":1},"css":{"modules\/system\/system.base.css":1,"misc\/ui\/jquery.ui.core.css":1,"misc\/ui\/jquery.ui.theme.css":1,"misc\/ui\/jquery.ui.menu.css":1,"misc\/ui\/jquery.ui.autocomplete.css":1,"misc\/ui\/jquery.ui.button.css":1,"misc\/ui\/jquery.ui.resizable.css":1,"misc\/ui\/jquery.ui.dialog.css":1,"sites\/all\/modules\/contrib\/codefilter\/codefilter.css":1,"sites\/all\/modules\/contrib\/date\/date_api\/date.css":1,"sites\/all\/modules\/contrib\/date\/date_popup\/themes\/datepicker.1.7.css":1,"sites\/all\/modules\/contrib\/date\/date_repeat_field\/date_repeat_field.css":1,"modules\/field\/theme\/field.css":1,"modules\/node\/node.css":1,"sites\/all\/modules\/custom\/nvidia_quick_survey\/nvidia_quick_survey.css":1,"sites\/all\/modules\/contrib\/views\/css\/views.css":1,"sites\/all\/modules\/contrib\/ctools\/css\/ctools.css":1,"sites\/all\/modules\/custom\/nvidia_tokens\/css\/nvidia-charts.css":1,"https:\/\/developer.nvidia.com\/register\/dz-auth.css?v=3.2.5c":1,"sites\/all\/modules\/contrib\/addtoany\/addtoany.css":1,"sites\/all\/themes\/bootstrap\/css\/overrides.css":1,"sites\/all\/themes\/devzone_base\/css\/application.css":1}},"colorbox":{"opacity":"0.85","current":"{current} of {total}","previous":"\u00ab Prev","next":"Next \u00bb","close":"Close","maxWidth":"98%","maxHeight":"98%","fixed":true,"mobiledetect":true,"mobiledevicewidth":"480px"},"gss":{"key":"000841979776854404513:41w2zzjvamy"},"urlIsAjaxTrusted":{"\/gpugems\/gpugems2\/part-ii-shading-lighting-and-shadows\/chapter-16-accurate-atmospheric-scattering":true},"bootstrap":{"anchorsFix":1,"anchorsSmoothScrolling":1,"formHasError":1,"popoverEnabled":1,"popoverOptions":{"animation":1,"html":0,"placement":"right","selector":"","trigger":"click","triggerAutoclose":1,"title":"","content":"","delay":0,"container":"body"},"tooltipEnabled":1,"tooltipOptions":{"animation":1,"html":0,"placement":"auto left","selector":"","trigger":"hover focus","delay":0,"container":"body"}}});</script>
</head>
<body class="html not-front not-logged-in no-sidebars page-taxonomy page-taxonomy-term page-taxonomy-term- page-taxonomy-term-1372" >
  <div id="skip-link">
    <a href="#main-content" class="element-invisible element-focusable">Skip to main content</a>
  </div>
    

  <!--Navbar-->
  <nav class="navbar navbar-inverse navbar-static-top" role="navigation"
       id="nvidia-dropdown">
    <div class="container">
      <div class="navbar-header">
        <button class="navbar-toggle" type="button"><span
            class="icon-bar"></span><span class="icon-bar"></span><span
            class="icon-bar"></span></button>
        <div class="logo-header">
          <a class="navbar-brand first-logo" href="/"
             title="Home">
            <img alt="Home"
                 src="/sites/all/themes/devzone_base/images/nvidia.png"/>
          </a>
          <a class="navbar-brand second-logo"
             href="/"
             title="Home">
            <img alt="Home"
                 src="https://developer.nvidia.com/sites/all/themes/devzone_base/logo.png"/>
          </a>
        </div>
      </div>
      <div class="collapse navbar-collapse" id="navbar-collapse">

                  <ul class="menu nav navbar-nav primary"><li class="first expanded megamenu dropdown"><a class="dropdown-toggle nolink" data-target="#" data-toggle="dropdown">Solutions <span class="caret"></span></a><div class="dropdown-menu"><div class="container-fluid"><ul class="navbar-nav"><li class="first expanded dropdown"><a class="nolink">AI and Deep Learning</a><ul><li class="first leaf"><a href="/deep-learning">Deep Learning</a></li>
<li class="leaf"><a href="/machine-learning">Machine Learning</a></li>
<li class="leaf"><a href="/tensorrt">Inference</a></li>
<li class="leaf"><a href="https://www.nvidia.com/en-us/deep-learning-ai/education" title="">Deep Learning Institute</a></li>
<li class="leaf"><a href="/Clara-Genomics">Genomics</a></li>
<li class="last leaf"><a href="https://www.nvidia.com/en-us/gpu-cloud/" title="">GPU-optimized S/W (NGC)</a></li>
</ul></li>
<li class="expanded dropdown"><a href="https://developer.nvidia.com/embedded-computing">Autonomous Machines</a><ul><li class="first leaf"><a href="/embedded/develop/hardware">Hardware (Jetson)</a></li>
<li class="leaf"><a href="/isaac-sdk" title="">Robotics</a></li>
<li class="last leaf"><a href="/deepstream-sdk" title="">Video Analytics</a></li>
</ul></li>
<li class="expanded dropdown"><a href="/drive">Autonomous Vehicles</a><ul><li class="first leaf"><a href="/drive/drive-agx">Hardware (DRIVE AGX)</a></li>
<li class="leaf"><a href="/drive/drive-hyperion" title="">Reference Architecture</a></li>
<li class="leaf"><a href="/drive/drive-software">Autonomous Vehicle Software</a></li>
<li class="last leaf"><a href="/drive/drive-constellation">Data Center Simulation Platform</a></li>
</ul></li>
<li class="expanded dropdown"><a href="/rtx">Graphics and Simulation</a><ul><li class="first leaf"><a href="https://developer.nvidia.com/graphics-research-tools" title="">Graphics Research Tools</a></li>
<li class="leaf"><a href="/video-processing">Video Processing</a></li>
<li class="leaf"><a href="/rtx/raytracing" title="">Ray Tracing</a></li>
<li class="leaf"><a href="/rtx/ngx" title="">AI for Graphics</a></li>
<li class="leaf"><a href="/gameworks-visualfx-overview" title="">Real-time VFX</a></li>
<li class="leaf"><a href="/vrworks">Virtual and Augmented Reality</a></li>
<li class="leaf"><a href="/physx-sdk">Simulation</a></li>
<li class="leaf"><a href="/clara">Medical Imaging</a></li>
<li class="leaf"><a href="/index">Scientific Visualization</a></li>
<li class="last leaf"><a href="https://www.nvidia.com/en-us/design-visualization/solutions/quadro-display-desktop-management#Management">Display</a></li>
</ul></li>
<li class="expanded dropdown"><a href="/hpc">High-performance Computing</a><ul><li class="first leaf"><a href="/language-solutions">Languages and APIs</a></li>
<li class="leaf"><a href="/gpu-accelerated-libraries">GPU Accelerated Libraries</a></li>
<li class="last leaf"><a href="/openacc">OpenACC Programming Model</a></li>
</ul></li>
<li class="last expanded dropdown"><a href="/tools-overview">Tools and Management</a><ul><li class="first leaf"><a href="/tools-overview" title="">Developer Tools</a></li>
<li class="leaf"><a href="/what-is-designworks">Management Tools</a></li>
<li class="last leaf"><a href="/tools-overview">Android and Tegra for Mobile</a></li>
</ul></li>
</ul></div></div></li>
<li class="expanded megamenu dropdown"><a class="dropdown-toggle nolink" data-target="#" data-toggle="dropdown">Platforms <span class="caret"></span></a><div class="dropdown-menu"><div class="container-fluid"><ul class="navbar-nav"><li class="first expanded dropdown"><a class="nolink">CUDA-X AI</a><ul><li class="first leaf"><a href="/tensorrt">TensorRT</a></li>
<li class="leaf"><a href="/cudnn">cuDNN</a></li>
<li class="leaf"><a href="/nccl">NCCL</a></li>
<li class="leaf"><a href="/cublas">cuBLAS</a></li>
<li class="leaf"><a href="/cusparse">cuSPARSE</a></li>
<li class="leaf"><a href="/deepstream-sdk">DeepStream SDK</a></li>
<li class="leaf"><a href="/opticalflow-sdk">Optical Flow SDK</a></li>
<li class="leaf"><a href="/DALI">DALI</a></li>
<li class="leaf"><a href="/transfer-learning-toolkit">Transfer Learning Toolkit</a></li>
<li class="last leaf"><a href="/digits">DIGITS</a></li>
</ul></li>
<li class="expanded dropdown"><a class="nolink">CLARA</a><ul><li class="first leaf"><a href="/clara-medical-imaging">Clara Train</a></li>
<li class="leaf"><a href="/clara-medical-imaging">Clara Deploy</a></li>
<li class="last leaf"><a href="/Clara-Genomics">Clara Genomics SDK</a></li>
</ul></li>
<li class="expanded dropdown"><a class="nolink">HPC</a><ul><li class="first leaf"><a href="/cuda-zone">CUDA Toolkit</a></li>
<li class="last leaf"><a href="/openacc">OpenACC</a></li>
</ul></li>
<li class="expanded dropdown"><a class="nolink">DRIVE</a><ul><li class="first leaf"><a href="/drive/drive-agx">DRIVE AGX</a></li>
<li class="leaf"><a href="/drive/drive-hyperion">DRIVE Hyperion</a></li>
<li class="leaf"><a href="/drive/drive-constellation">DRIVE Sim</a></li>
<li class="leaf"><a href="/drive/drive-constellation">DRIVE Constellation</a></li>
<li class="last leaf"><a href="https://www.nvidia.com/en-us/data-center/dgx-systems/">DGX</a></li>
</ul></li>
<li class="expanded dropdown"><a class="nolink">RTX</a><ul><li class="first leaf"><a href="/optix">OptiX SDK</a></li>
<li class="leaf"><a href="/vrworks/vrworks-audio" title="">Path-traced Audio (VRWorks) </a></li>
<li class="leaf"><a href="/Vulkan">VKRay</a></li>
<li class="leaf"><a href="/mdl-sdk">MDL SDK</a></li>
<li class="leaf"><a href="/vmaterials">vMaterials</a></li>
<li class="leaf"><a href="/physx-sdk">PhysX</a></li>
<li class="leaf"><a href="/flex">Flex</a></li>
<li class="leaf"><a href="/opticalflow-sdk" title="">Optical Flow SDK</a></li>
<li class="leaf"><a href="/nvidia-video-codec-sdk">Video Codec SDK</a></li>
<li class="last leaf"><a href="/gpudirectforvideo">GPUDirect for Video</a></li>
</ul></li>
<li class="expanded dropdown"><a class="nolink">ISAAC</a><ul><li class="first leaf"><a href="/embedded/develop/hardware">Jetson Developer Kits</a></li>
<li class="leaf"><a href="/embedded/jetpack" title="">Jetpack</a></li>
<li class="leaf"><a href="/isaac-sdk">Isaac Robot Engine</a></li>
<li class="last leaf"><a href="/isaac-sdk">Isaac Sim</a></li>
</ul></li>
<li class="last expanded dropdown"><a class="nolink">Metropolis</a><ul><li class="first last leaf"><a href="/deepstream-sdk" title="">DeepStream SDK</a></li>
</ul></li>
</ul></div></div></li>
<li class="expanded dropdown"><a class="dropdown-toggle nolink" data-target="#" data-toggle="dropdown">Documentation <span class="caret"></span></a><div class="dropdown-menu"><ul><li class="first leaf"><a href="https://docs.nvidia.com">Library</a></li>
<li class="leaf"><a href="https://raytracing-docs.nvidia.com/">Ray Tracing</a></li>
<li class="leaf"><a href="https://docs.nvidia.com/cuda/index.html">CUDA Toolkit</a></li>
<li class="leaf"><a href="https://docs.nvidia.com/gameworks/index.html">GameWorks</a></li>
<li class="leaf"><a href="https://docs.nvidia.com/drive/index.html">DRIVE</a></li>
<li class="leaf"><a href="https://docs.nvidia.com/ngc/index.html">NGC</a></li>
<li class="last leaf"><a href="https://docs.nvidia.com/isaac/index.html">Isaac</a></li>
</ul></div></li>
<li class="expanded dropdown"><a class="dropdown-toggle nolink" data-target="#" data-toggle="dropdown">Downloads <span class="caret"></span></a><div class="dropdown-menu"><ul><li class="first leaf"><a href="/cuda-toolkit" title="">CUDA Toolkit</a></li>
<li class="leaf"><a href="https://developer.nvidia.com/gameworksdownload#?cl=date,-1&amp;tx=$gameworks,developer_tools" title="">Developer Tools</a></li>
<li class="leaf"><a href="/clara">CLARA</a></li>
<li class="leaf"><a href="/drive/downloads">DRIVE</a></li>
<li class="leaf"><a href="https://developer.nvidia.com/graphics-research-tools" title="">Graphics Research Tools</a></li>
<li class="leaf"><a href="/gameworksdownload">Gameworks</a></li>
<li class="leaf"><a href="/isaac-sdk">Isaac</a></li>
<li class="leaf"><a href="/embedded/downloads">Jetson</a></li>
<li class="last leaf"><a href="/deepstream-sdk">Metropolis</a></li>
</ul></div></li>
<li class="expanded dropdown"><a class="dropdown-toggle nolink" data-target="#" data-toggle="dropdown">Resources <span class="caret"></span></a><div class="dropdown-menu"><ul><li class="first leaf"><a href="/contact">Contact Us</a></li>
<li class="leaf"><a href="/developer-program">Developer Program</a></li>
<li class="leaf"><a href="https://courses.nvidia.com">Deep Learning Institute</a></li>
<li class="leaf"><a href="/higher-education-and-research">Educators</a></li>
<li class="leaf"><a href="https://ngc.nvidia.com">NGC</a></li>
<li class="leaf"><a href="https://on-demand-gtc.gputechconf.com">GTC Videos</a></li>
<li class="last leaf"><a href="/open-source">Open Source</a></li>
</ul></div></li>
<li class="last expanded dropdown"><a class="dropdown-toggle nolink" data-target="#" data-toggle="dropdown">Community <span class="caret"></span></a><div class="dropdown-menu"><ul><li class="first leaf"><a href="https://forums.developer.nvidia.com" title="">Forums</a></li>
<li class="leaf"><a href="https://devblogs.nvidia.com">Blog</a></li>
<li class="last leaf"><a href="https://news.developer.nvidia.com">News</a></li>
</ul></div></li>
</ul>                <ul
          class="nav navbar-nav navbar-margin navbar-right navbar-margin-media login-nav">
                      <li class="search" id="search-top">
              <div class="search-form" id="search-top-form">
                <form class="gss form-search content-search" action="/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-16-accurate-atmospheric-scattering" method="post" id="search-block-form" accept-charset="UTF-8"><div><div>
      <h2 class="element-invisible">Search form</h2>
    <div class="input-group"><input title="Enter the terms you wish to search for." placeholder="Search..." class="form-control form-text" type="text" id="edit-search-block-form--2" name="search_block_form" value="" size="15" maxlength="128" /><span class="input-group-btn"><button type="submit" class="btn btn-default"><span class="icon glyphicon glyphicon-search" aria-hidden="true"></span>
</button></span></div><div class="form-actions form-wrapper form-group" id="edit-actions"><button class="element-invisible btn btn-primary form-submit" type="submit" id="edit-submit" name="op" value="Search">Search</button>
</div><input type="hidden" name="form_build_id" value="form-5xhoI6fqee27n6KZ-J_U1iY2vHq5wZJO-VyLyhuAMHA" />
<input type="hidden" name="form_id" value="search_block_form" />
</div>
</div></form>              </div>
            </li>
          
          
          
                      <li class="leaf last" id="dzauth_login_link"><a href="javascript:jQuery.sidr('close');javascript:showDzAuth('login');">Account</a></li>
          
        </ul>
      </div>
    </div>
  </nav>
      <nav class="navbar navbar-inverse second-navbar hidden-xs" role="navigation"
         id="nvidia-secondary-dropdown">
      <div class="container">
        <div class="collapse navbar-collapse">
          <ul class="menu nav navbar-nav secondary"><li class="first leaf"><a href="/rtx" title="">RTX</a></li>
<li class="leaf"><a href="/gameworks" title="">GAMEWORKS</a></li>
<li class="leaf"><a href="/designworks" title="">DESIGNWORKS</a></li>
<li class="leaf"><a href="/vrworks" title="">VRWORKS</a></li>
<li class="leaf"><a href="/hpc" title="">HPC</a></li>
<li class="leaf"><a href="/deepstream-sdk" title="">METROPOLIS</a></li>
<li class="leaf"><a href="/drive" title="">DRIVE</a></li>
<li class="leaf"><a href="/clara" title="">CLARA</a></li>
<li class="last leaf"><a href="/open-source" title="">OPEN SOURCE</a></li>
</ul>                  </div>
      </div>
    </nav>
  <div id="wrapper">
        
  <div id="content-background"
       class="white-background">
          <div id='console'>
        <div class="container">
                            </div>
      </div>
    
    <div class="separator"></div>
    <div id="content" class="container">
              <ol class="breadcrumb hidden-xs"><li><a href="/">Home</a></li><li><a href="/gpugems/gpugems2">GPUGems2</a></li><li class="active"><a href="/gpugems/gpugems2/part-ii-shading-lighting-and-shadows">Part II: Shading, Lighting, and Shadows</a></li></ol>      
                      <div class="separator"></div>
      
      
      <div class="row">

        
        <section  class="col-sm-12">
          
                    <a id="main-content"></a>

<<<<<<< HEAD
            <div class="region region-content">
=======
            <div class="region region-content">
>>>>>>> 17e2c9f0015b84508c0980fb762a587738dc55ae
    <section id="block-system-main" class="block block-system clearfix">

      
  <div class="term-listing-heading">
<div id="book_switch">
  <a href="/gpugems/gpugems" class="btn btn-primary">GPUGems</a><a href="/gpugems/gpugems2" class="btn btn-primary">GPUGems2</a><a href="/gpugems/gpugems3" class="btn btn-primary">GPUGems3</a></div>
<div id="book_page">
  <div class="row">
    <div class="col-md-8">
<<<<<<< HEAD
      <a href="http://developer.nvidia.com/gpugems2"><img src="/sites/all/modules/custom/gpugems/books/GPUGems2/GPU_Gems_2.jpg" align="left" border="0" hspace="5"></a>        <h1><a href="http://developer.nvidia.com/gpugems2">GPU Gems 2</a></h1> <b>GPU Gems 2</b> is now available, right here, online. You can <a href="http://www.informit.com/promotion/136275">purchase a beautifully printed version       of this book</a>, and others in the series, at a 30% discount courtesy of InformIT and Addison-Wesley.<br>       <br>     
=======
      <a href="http://developer.nvidia.com/gpugems2"><img src="/sites/all/modules/custom/gpugems/books/GPUGems2/GPU_Gems_2.jpg" align="left" border="0" hspace="5"></a>        <h1><a href="http://developer.nvidia.com/gpugems2">GPU Gems 2</a></h1> <b>GPU Gems 2</b> is now available, right here, online. You can <a href="http://www.informit.com/promotion/136275">purchase a beautifully printed version       of this book</a>, and others in the series, at a 30% discount courtesy of InformIT and Addison-Wesley.<br>       <br>     
>>>>>>> 17e2c9f0015b84508c0980fb762a587738dc55ae
The CD content, including demos and content, is available on the <a target="_blank" href="https://http.download.nvidia.com/developer/GPU_Gems_2/CD/Index.html">web</a> and for <a href="https://http.download.nvidia.com/developer/GPU_Gems_2/CD/GPU_Gems_2_code.zip">download</a>.<br>       <br>       <br clear="all">       <hr>      <h1 class="docChapterTitle" data-parent="Part II: Shading, Lighting, and Shadows">Chapter 16. Accurate Atmospheric Scattering</h1>        <p><em>Sean O'Neil</em></p>        <h2>16.1 Introduction</h2>        <p>Generating realistic atmospheric scattering for computer graphics has always been a difficult problem, but it is very important for rendering realistic outdoor environments. The equations that describe atmospheric scattering are so complex       that entire books have been dedicated to the subject. Computer graphics models generally use simplified equations, and very few of them run at interactive frame rates. This chapter explains how to implement a real-time atmospheric scattering       algorithm entirely on the GPU using the methods described in Nishita et al. 1993. Figure 16-1 shows screenshots from the scattering demo included on this book's CD.</p>        <div class="figure" align="center">         <img src="/sites/all/modules/custom/gpugems/books/GPUGems2/elementLinks/16_atmospheric_01a.jpg" alt="16_atmospheric_01a.jpg" />          <p>Figure 16-1 Screenshots from the Scattering Demo</p>       </div>        <p>Many atmospheric scattering models assume that the camera is always on or very close to the ground. This makes it easier to assume that the atmosphere has a constant density at all altitudes, which simplifies the scattering equations in       Nishita et al. 1993 tremendously. Refer to Hoffman and Preetham 2002 for an explanation of how to implement these simplified equations in a GPU shader. This implementation produces an attractive scattering effect that is very fast on DirectX       8.0 shaders. Unfortunately, it doesn't always produce very accurate results, and it doesn't work well for a flight or space simulator, in which the camera can be located in space or very high above the ground.</p>        <p>This chapter explains how to implement the full equations from Nishita et al. 1993 in a GPU shader that runs at interactive frame rates. These equations model the atmosphere more accurately, with density falling off exponentially as       altitude increases. O'Neil 2004 describes a similar algorithm that ran on the CPU, but that algorithm was too CPU-intensive. It was based on a precalculated 2D lookup table with four floating-point channels. Calculating the color for each       vertex required several lookups into the table, with extra calculations around each lookup. At the time that article was written, no GPU could support such operations in a shader in one pass.</p>        <p>In this chapter, we eliminate the lookup table without sacrificing image quality, allowing us to implement the entire algorithm in a GPU shader. These shaders are small and fast enough to run in real time on most GPUs that support DirectX       Shader Model 2.0.</p>        <h2>16.2 Solving the Scattering Equations</h2>        <p>The scattering equations have nested integrals that are impossible to solve analytically; fortunately, it's easy to numerically compute the value of an integral with techniques such as the trapezoid rule. Approximating an integral in this       manner boils down to a weighted sum calculated in a loop. Imagine a line segment on a graph: break up the segment into <em>n</em> sample segments and evaluate the integrand at the center point of each sample segment. Multiply each result by       the length of the sample segment and add them all up. Taking more samples makes the result more accurate, but it also makes the integral more expensive to calculate.</p>        <p>In our case, the line segment is a ray from the camera through the atmosphere to a vertex. This vertex can be part of the terrain, part of the sky dome, part of a cloud, or even part of an object in space such as the moon. If the ray passes       through the atmosphere to get to the vertex, scattering needs to be calculated. Every ray should have two points defined that mark where the ray starts passing through the atmosphere and where it stops passing through the atmosphere. We'll       call these points <em>A</em> and <em>B</em>, and they are shown in Figure 16-2. When the camera is inside the atmosphere, <em>A</em> is the camera's position. When the vertex is inside the atmosphere, <em>B</em> is the vertex's position. When       either point is in space, we perform a sphere-intersection check to find out where the ray intersects the outer atmosphere, and then we make the intersection point <em>A</em> or <em>B</em>.</p>        <div class="figure" align="center">         <img src="/sites/all/modules/custom/gpugems/books/GPUGems2/elementLinks/16_atmospheric_02.jpg" alt="16_atmospheric_02.jpg" />          <p>Figure 16-2 The Geometry of Atmospheric Scattering</p>       </div>        <p>Now we have a line segment defined from point <em>A</em> to point <em>B</em>, and we want to approximate the integral that describes the atmospheric scattering across its length. For now let's take five sample positions and name their       points <em>P</em> <sub>1</sub> through <em>P</em> <sub>5</sub>. Each point <em>P</em> <sub>1</sub> through <em>P</em> <sub>5</sub> represents a point in the atmosphere at which light scatters; light comes into the atmosphere from the sun,       scatters at that point, and is reflected toward the camera. Consider the point <em>P</em> <sub>5</sub>, for example. Sunlight goes directly from the sun to <em>P</em> <sub>5</sub> in a straight line. Along that line the atmosphere scatters       some of the light away from <em>P</em> <sub>5</sub>. At <em>P</em> <sub>5</sub>, some of this light is scattered directly toward the camera. As the light from <em>P</em> <sub>5</sub> travels to the camera, some of it gets scattered away       again.</p>        <h4>16.2.1 Rayleigh Scattering vs. Mie Scattering</h4>        <p>Another important detail is related to how the light scattering at the point <em>P</em> is modeled. Different particles in the atmosphere scatter light in different ways. The two most common forms of scattering in the atmosphere are       <em>Rayleigh</em> <em>scattering</em> and <em>Mie scattering</em>. Rayleigh scattering is caused by small molecules in the air, and it scatters light more heavily at the shorter wavelengths (blue first, then green, and then red). The sky is       blue because the blue light bounces all over the place, and ultimately reaches your eyes from every direction. The sun's light turns yellow/orange/red at sunset because as light travels far through the atmosphere, almost all of the blue and       much of the green light is scattered away before it reaches you, leaving just the reddish colors.</p>        <p>Mie scattering is caused by larger particles in the air called aerosols (such as dust and pollution), and it tends to scatter all wavelengths of light equally. On a hazy day, Mie scattering causes the sky to look a bit gray and causes the       sun to have a large white halo around it. Mie scattering can also be used to simulate light scattered from small particles of water and ice in the air, to produce effects like rainbows, but that is beyond the scope of this chapter. (Refer to       Brewer 2004 for more information.)</p>        <h4>16.2.2 The Phase Function</h4>        <p><img src="/sites/all/modules/custom/gpugems/books/GPUGems2/elementLinks/0256equ01.jpg" alt="0256equ01.jpg" /></p>        <p>The phase function describes how much light is scattered toward the direction of the camera based on the angle <em></em> (the angle between the two green rays in Figure 16-2) and a constant <em>g</em> that       affects the symmetry of the scattering. There are many different versions of the phase function. This one is an adaptation of the Henyey-Greenstein function used in Nishita et al. 1993.</p>        <p>Rayleigh scattering can be approximated by setting <em>g</em> to 0, which greatly simplifies the equation and makes it symmetrical for positive and negative angles. Negative values of <em>g</em> scatter more light in a forward direction,       and positive values of <em>g</em> scatter more light back toward the light source. For Mie aerosol scattering, <em>g</em> is usually set between -0.75 and -0.999. Never set <em>g</em> to 1 or -1, as it makes the equation reduce to 0.</p>        <h4>16.2.3 The Out-Scattering Equation</h4>        <p><img src="/sites/all/modules/custom/gpugems/books/GPUGems2/elementLinks/0256equ02.jpg" alt="0256equ02.jpg" /></p>        <p>The out-scattering equation is the inner integral mentioned earlier. The integral part determines the "optical depth," or the average atmospheric density across the ray from point <em>P<sub>a</sub></em> to point <em>P<sub>b</sub></em>       multiplied by the length of the ray. This is also called the "optical length" or "optical thickness." Think of it as a weighting factor based on how many air particles are in the path of the light along the ray. The rest of the equation is       made up of constants, and they determine how much of the light those particles scatter away from the ray.</p>        <p>To compute the value of this integral, the ray from <em>P<sub>a</sub></em> to <em>P<sub>b</sub></em> will be broken up into segments and the exponential term will be evaluated at each sample point. The variable <em>h</em> is the height of       the sample point. In my implementation, the height is scaled so that 0 represents sea level and 1 is at the top of the atmosphere. In theory, the atmosphere has no fixed top, but for practical purposes, we have to choose some height at which       to render the sky dome. <em>H</em> <sub>0</sub> is the scale height, which is the height at which the atmosphere's average density is found. My implementation uses 0.25, so the average density is found 25 percent of the way up from the ground       to the sky dome.</p>        <p>The constant  is the wavelength (or color) of light and <em>K</em>() is the scattering constant, which is dependent on the density of the atmosphere at sea level. Rayleigh and Mie       scattering each have their own scattering constants, including the scale height (<em>H</em> <sub>0</sub>). Rayleigh and Mie scattering also differ in how they depend on wavelength. The Rayleigh scattering constant is usually divided by       <sup>4</sup>. In most computer graphics models, the Mie scattering constant is not dependent on wavelength, but at least one implementation divides it by <sup>0.84</sup>. Wherever this       equation depends on wavelength, it must be solved separately for each of the three color channels and separately for each type of scattering.</p>        <h4>16.2.4 The In-Scattering Equation</h4>        <p><img src="/sites/all/modules/custom/gpugems/books/GPUGems2/elementLinks/0257equ01.jpg" alt="0257equ01.jpg" /></p>        <p>The in-scattering equation describes how much light is added to a ray through the atmosphere due to light scattering from the sun. For each point <em>P</em> along the ray from <em>P<sub>a</sub></em> to <em>P<sub>b</sub></em> ,       <em>PP<sub>c</sub></em> is the ray from the point to the sun and <em>PPa</em> is the ray from the sample point to the camera. The out-scattering function determines how much light is scattered away along the two green rays in Figure 16-2. The       remaining light is scaled by the phase function, the scattering constant, and the intensity of the sunlight, <em>I<sub>s</sub></em> (). The sunlight intensity does not have to be dependent on wavelength, but this is       where you would apply the color if you wanted to create an alien world revolving around a purple star.</p>        <h4>16.2.5 The Surface-Scattering Equation</h4>        <table>         <tbody>           <tr>             <td>               <p><em>I'<sub>v</sub></em> () = <em>I<sub>v</sub></em> () + <em>I</em> <sub>e</sub>() x exp (&#x2013;t (<em>P<sub>a</sub> P<sub>b</sub></em> ,               ))</p>             </td>           </tr>         </tbody>       </table>        <p>To scatter light reflected from a surface, such as the surface of a planet, you must take into account the fact that some of the reflected light will be scattered away on its way to the camera. In addition, extra light is scattered in from       the atmosphere. <em>I<sub>e</sub></em> () is the amount of light emitted or reflected from a surface, and it is attenuated by an out-scattering factor. The sky is not a surface that can reflect or emit light, so       only <em>I<sub>v</sub></em> () is needed to render the sky. Determining how much light is reflected or emitted by a surface is application-specific, but for reflected sunlight, you need to account for the       out-scattering that takes place before the sunlight strikes the surface (that is, <em>I<sub>s</sub></em> () x exp(-<em>t</em>(<em>P<sub>c</sub> P<sub>b</sub></em> ,))), and use that as       the color of the light when determining how much light the surface reflects.</p>        <h2>16.3 Making It Real-Time</h2>        <p>Let's find out how poorly these equations will perform if they're implemented as explained in the preceding section, with five sample points for the in-scattering equation and five sample points for each of the integrals to compute the       out-scattering equations. This gives 5 x (5 + 5) samples at which to evaluate the functions for each vertex. We also have two types of scattering, Rayleigh and Mie, and we have to calculate each one for the different wavelengths of each of the       three color channels (RGB). So now we're up to approximately 2 x 3 x 5 x (5 + 5), or 300 computations per vertex. To make matters worse, the visual quality suffers noticeably when using only five samples for each integral. O'Neil 2004 used 50       samples for the inner integrals and five for the outer integral, which pushes the number of calculations up to 3,000 per vertex!</p>        <p>We don't need to go any further to know that this will not run very fast. Nishita et al. 1993 used a precalculated 2D lookup table to cut the number of calculations in half, but it still won't run in real time. Their lookup table took       advantage of the fact that the sun is so far away that its rays can be considered parallel. (This idea is reflected in the in-scattering equation, in Section 16.2.4.) This makes it possible to calculate a lookup table that contains the amount       of out-scattering for rays going from the sun to any point in the atmosphere. This table replaces one of the out-scattering integrals with a lookup table whose variables are altitude and angle to the sun. Because the rays to the camera are not       parallel, the out-scattering integral for camera rays still had to be solved at runtime.</p>        <p>In O'Neil 2004, I proposed a better 2D lookup table that allows us to avoid both out-scattering integrals. The first dimension, <em>x</em>, takes a sample point at a specific altitude above the planet, with 0.0 being on the ground and 1.0       being at the top of the atmosphere. The second dimension, <em>y</em>, represents a vertical angle, with 0.0 being straight up and 1.0 being straight down. At each (<em>x</em>, <em>y</em>) pair in the table, a ray is fired from a point at       altitude <em>x</em> to the top of the atmosphere along angle <em>y</em>. The lookup table had four channels, two reserved for Rayleigh scattering and two reserved for Mie scattering. One channel for each simply contained the atmospheric       density at that altitude, or exp(-<em>h</em>/<em>H</em> <sub>0</sub>). The other channel contained the optical depth of the ray just described. Because the lookup table was precomputed, I chose to use 50 samples to approximate the optical       depth integral, resulting in very good accuracy.</p>        <p>As with the lookup table proposed in Nishita et al. 1993, we can get the optical depth for the ray to the sun from any sample point in the atmosphere. All we need is the height of the sample point (<em>x</em>) and the angle from vertical to       the sun (<em>y</em>), and we look up (<em>x</em>, <em>y</em>) in the table. This eliminates the need to calculate one of the out-scattering integrals. In addition, the optical depth for the ray to the camera can be figured out in the same way,       right? Well, almost. It works the same way when the camera is in space, but not when the camera is in the atmosphere. That's because the sample rays used in the lookup table go from some point at height <em>x</em> all the way to the top of the       atmosphere. They don't stop at some point in the middle of the atmosphere, as they would need to when the camera is inside the atmosphere.</p>        <p>Fortunately, the solution to this is very simple. First we do a lookup from sample point <em>P</em> to the camera to get the optical depth of the ray passing through the camera to the top of the atmosphere. Then we do a second lookup for       the same ray, but starting at the camera instead of starting at <em>P</em>. This will give us the optical depth for the part of the ray that we don't want, and we can subtract it from the result of the first lookup. Examine the rays starting       from the ground vertex (<em>B</em> <sub>1</sub>) in Figure 16-3 for a graphical representation of this.</p>        <div class="figure" align="center">         <img src="/sites/all/modules/custom/gpugems/books/GPUGems2/elementLinks/16_atmospheric_03.jpg" alt="16_atmospheric_03.jpg" />          <p>Figure 16-3Problems with the Improved Lookup Table</p>       </div>        <p>There's only one problem left. When a vertex is above the camera in the atmosphere, the ray from sample point <em>P</em> through the camera can pass through the planet itself. The height variable is not expected to go so far negative, and       it can cause the numbers in the lookup table to go extremely high, losing precision and sometimes even encountering a floating-point overflow. The way to avoid this problem is to reverse the direction of the rays when the vertex is above the       camera. Examine the rays passing through the sky vertex (<em>B</em> <sub>2</sub>) in Figure 16-3 for a graphical representation of this.</p>        <p>So now we've reduced 3,000 calculations per vertex to something closer to 2 x 3 x 5 x (1 + 1), or 60 (assuming five samples for the out-scattering integral for the eye ray). Implemented in software on an Athlon 2500+ with an inefficient       brute-force rendering method, I was able to get this method to run between 50 and 100 frames per second.</p>        <h2>16.4 Squeezing It into a Shader</h2>        <p>At this point, I felt that this algorithm had been squeezed about as much as it could, but I knew that I had to squeeze it even smaller to fit it into a shader. I didn't want this algorithm to require Shader Model 3.0, so having lookup       tables in textures used by the vertex shaders wasn't possible. I decided to take a different approach and started to mathematically analyze the results of the lookup table. Even though I knew I couldn't come up with a way to simplify the       integral equations, I had hoped that I might be able to simulate the results closely enough with a completely different equation.</p>        <h4>16.4.1 Eliminating One Dimension</h4>        <p>I started by plotting the results of the lookup table on a graph. I plotted height from 0.0 to 1.0 along the <em>x</em> axis and the lookup table result (optical depth) along the <em>y</em> axis. For various angles sampled from 0 to 1, I       plotted a separate line on the graph. I noticed right away that each line dropped off exponentially as <em>x</em> went from 0 to 1, but the scale of each line on the graph varied dramatically. This makes sense, because as the angle of the ray       goes from straight up to straight down, the length of the ray increases dramatically.</p>        <p>To make it easier to compare the shapes of the curves of each line, I decided to normalize them. I took the optical depth value at <em>x</em> = 0 (or height = 0) for each line and divided all of the values on that line by that value. This       scaled all lines on the graph to start at (<em>x</em> = 0, <em>y</em> = 1) and work their way down toward (<em>x</em> = 1, <em>y</em> = 0). To my surprise, almost all of the normalized lines fell right on top of each other on the graph! The       curve was almost exactly the same for every one, and that curve turned out to be exp(-4<em>x</em>).</p>        <p>This makes some sense, because the optical depth equation is the integral of exp(-<em>h</em>/<em>H</em> <sub>0</sub>). I chose <em>H</em> <sub>0</sub> to be 0.25, so exp(-4<em>h</em>) is a common factor. It is still a bit puzzling, however,       as the <em>h</em> inside the integral is not the same as the height <em>x</em> outside the integral, which is only the height at the start of the ray. The <em>h</em> value inside the integral does not vary linearly, and it has more to do with       how it passes through a spherical space than with the starting height. There is some variation in the lines, and the variation increases as the angle increases. The variation gets worse exponentially as the angle increases over 90 degrees.       Because we don't care about angles that are much larger than 90 degrees (because the ray passes through the planet), exp(-4<em>x</em>) works very well for eliminating the <em>x</em> axis of the lookup table.</p>        <h4>16.4.2 Eliminating the Other Dimension</h4>        <p>Now that the <em>x</em> dimension (height) of the lookup table is being handled by exp(-4<em>x</em>), we need to eliminate the <em>y</em> dimension (angle). The only part of the optical depth that is not handled by exp(-4<em>x</em>) is the       scale used to normalize the lines on the graph explained previously, which is the value of the optical depth at <em>x</em> = 0. So now we create a new graph by plotting the angle from 0 to 1 on the <em>x</em> axis and the scale of each angle       on the <em>y</em> axis. For lack of a better name, I call this the <em>scale function</em>.</p>        <p>The first time I looked at the scale function, I noticed that it started at 0.25 (the scale height) and increased on some sort of accelerating curve. Thinking that it might be exponential, I divided the scales by the scale height (to make       the graph start at 1) and took the natural logarithm of the result. The result was another accelerating curve that I didn't recognize. I tried a number of curves, but nothing fit well on all parts of the curve. I ended up using graphical       analysis software to find a "best fit" equation for the curve, and it came back with a polynomial equation that was not pretty but fit the values well.</p>        <p>One significant drawback to this implementation is that the scale function is dependent on the scale height and the ratio between the atmosphere's thickness and the planet's radius. If either value changes, you need to calculate a new scale       function. In the demo included on this book's CD, the atmosphere's thickness (the distance from the ground to the top of the atmosphere) is 2.5 percent of the planet's radius, and the scale height is 25 percent of the atmosphere's thickness.       The radius of the planet doesn't matter as long as those two values stay the same.</p>        <h2>16.5 Implementing the Scattering Shaders</h2>        <p>Now that the problem has been solved mathematically, let's look at how the demo was implemented. The C++ code for the demo is fairly simple. The <tt>gluSphere()</tt> function is called to render both the ground and the sky dome. The front       faces are reversed for the sky dome so that the inside of its sphere is rendered. It uses a simple rectangular Earth texture to make it possible to see how the ground scattering affects colors on the ground, and it uses a simple glow texture       billboard to render the moon. No distinct sun is rendered, but the Mie scattering creates a glow in the sky dome that looks like the sun (only when seen through the atmosphere).</p>        <p>I have provided shader implementations in both Cg and GLSL on the book's CD. The ground, the sky, and objects in space each have two scattering shaders, one for when the camera is in space and one for when the camera is in the atmosphere       (this avoids conditional branching in the shaders). The ground shaders can be used for the terrain, as well as for objects that are beneath the camera. The sky shaders can be used for the sky dome, as well as for objects that are above the       camera. The space shaders can be used for any objects outside the atmosphere, such as the moon.</p>        <p>The naming convention for the shaders is "<em>render_object</em> From <em>camera_position</em>". So the SkyFromSpace shader is used to render the sky dome when the camera is in space. There is also a common shader that contains some common       constants and helper functions used throughout the shaders. Let's use SkyFromSpace as an example.</p>        <h4>16.5.1 The Vertex Shader</h4>        <p>As you can see in Listing 16-1, SkyFromSpace.vert is a fairly complex vertex shader, but hopefully it's easy enough to follow with the comments in the code and the explanations provided here. <tt>Kr</tt> is the Rayleigh scattering constant,       <tt>Km</tt> is the Mie scattering constant, and <tt>ESun</tt> is the brightness of the sun. Rayleigh scatters different wavelengths of light at different rates, and the ratio is <tt>1/pow(wavelength, 4)</tt>. Referring back to Figure 16-2,       <tt>v3Start</tt> is point <em>A</em> from the previous examples and <tt>v3Start + fFar</tt> * <tt>v3Ray</tt> is point <em>B</em>. The variable <tt>v3SamplePoint</tt> goes from <em>P</em> <sub>1</sub> to <em>P<sub>n</sub></em> with each       iteration of the loop.</p>        <p>The variable <tt>fStartOffset</tt> is actually the value of the lookup table from point <em>A</em> going toward the camera. Why would we need to calculate this when it's at the outer edge of the atmosphere? Because the density is not truly       zero at the outer edge. The density falls off exponentially and it is close to zero, but if we do not calculate this value and use it as an offset, there may be a visible "jump" in color when the camera enters the atmosphere.</p>        <p>You may have noticed that the phase function is missing from this shader. The phase function depends on the angle toward the light source, and it suffers from tessellation artifacts if it is calculated per vertex. To avoid these artifacts,       the phase function is implemented in the fragment shader.</p>        <h4>Example 16-1. SkyFromSpace.vert, Which Renders the Sky Dome When the Camera Is in Space</h4>       <pre> <strong><span style="color: rgb(0, 113, 188);">#include</span></strong> "Common.cg"    <strong><span style="color: rgb(0, 113, 188);">vertout</span></strong> main(<strong><span style="color: rgb(0, 113, 188);">float4</span></strong> gl_Vertex : <strong><span style="color: rgb(0, 113, 188);">POSITION</span></strong>,    <strong><span style="color: rgb(0, 113, 188);">uniform float4x4</span></strong> gl_ModelViewProjectionMatrix,    <strong><span style="color: rgb(0, 113, 188);">uniform float3</span></strong> v3CameraPos,     <strong><span style="color: rgb(156, 172, 59);">// The camera's current position</span></strong>      <strong><span style="color: rgb(0, 113, 188);">uniform float3</span></strong> v3LightDir,      <strong><span style="color: rgb(156, 172, 59);">// Direction vector to the light source</span></strong>    <strong><span style="color: rgb(0, 113, 188);">uniform float3</span></strong> v3InvWavelength, <strong><span style="color: rgb(156, 172, 59);">// 1 / pow(wavelength, 4) for RGB</span></strong>    <strong><span style="color: rgb(0, 113, 188);">uniform float</span></strong> fCameraHeight,    <strong><span style="color: rgb(156, 172, 59);">// The camera's current height</span></strong>      <strong><span style="color: rgb(0, 113, 188);">uniform float</span></strong> fCameraHeight2,   <strong><span style="color: rgb(156, 172, 59);">// fCameraHeight^2</span></strong>    <strong><span style="color: rgb(0, 113, 188);">uniform float</span></strong> fOuterRadius,     <strong><span style="color: rgb(156, 172, 59);">// The outer (atmosphere) radius</span></strong>    <strong><span style="color: rgb(0, 113, 188);">uniform float</span></strong> fOuterRadius2,    <strong><span style="color: rgb(156, 172, 59);">// fOuterRadius^2</span></strong>      <strong><span style="color: rgb(0, 113, 188);">uniform float</span></strong> fInnerRadius,     <strong><span style="color: rgb(156, 172, 59);">// The inner (planetary) radius</span></strong>    <strong><span style="color: rgb(0, 113, 188);">uniform float</span></strong> fInnerRadius2,    <strong><span style="color: rgb(156, 172, 59);">// fInnerRadius^2</span></strong>    <strong><span style="color: rgb(0, 113, 188);">uniform float</span></strong> fKrESun,          <strong><span style="color: rgb(156, 172, 59);">// Kr * ESun</span></strong>      <strong><span style="color: rgb(0, 113, 188);">uniform float</span></strong> fKmESun,          <strong><span style="color: rgb(156, 172, 59);">// Km * ESun</span></strong>    <strong><span style="color: rgb(0, 113, 188);">uniform float</span></strong> fKr4PI,           <strong><span style="color: rgb(156, 172, 59);">// Kr * 4 * PI</span></strong>    <strong><span style="color: rgb(0, 113, 188);">uniform float</span></strong> fKm4PI,           <strong><span style="color: rgb(156, 172, 59);">// Km * 4 * PI</span></strong>      <strong><span style="color: rgb(0, 113, 188);">uniform float</span></strong> fScale,           <strong><span style="color: rgb(156, 172, 59);">// 1 / (fOuterRadius - fInnerRadius)</span></strong>    <strong><span style="color: rgb(0, 113, 188);">uniform float</span></strong> fScaleOverScaleDepth) <strong><span style="color: rgb(156, 172, 59);">// fScale / fScaleDepth</span></strong>  {    <strong><span style="color: rgb(156, 172, 59);">// Get the ray from the camera to the vertex and its length (which</span></strong>    <strong><span style="color: rgb(156, 172, 59);">// is the far point of the ray passing through the atmosphere)</span></strong>      <strong><span style="color: rgb(0, 113, 188);">float3</span></strong> v3Pos = gl_Vertex.xyz;    <strong><span style="color: rgb(0, 113, 188);">float3</span></strong> v3Ray = v3Pos - v3CameraPos;    <strong><span style="color: rgb(0, 113, 188);">float</span></strong> fFar = <strong><span style="color: rgb(0, 113, 188);">length</span></strong>(v3Ray);    v3Ray /= fFar;      <strong><span style="color: rgb(156, 172, 59);">// Calculate the closest intersection of the ray with</span></strong>    <strong><span style="color: rgb(156, 172, 59);">// the outer atmosphere (point A in Figure 16-3)</span></strong>      <strong><span style="color: rgb(0, 113, 188);">float</span></strong> fNear = getNearIntersection(v3CameraPos, v3Ray, fCameraHeight2,                                      fOuterRadius2);      <strong><span style="color: rgb(156, 172, 59);">// Calculate the ray's start and end positions in the atmosphere,</span></strong>    <strong><span style="color: rgb(156, 172, 59);">// then calculate its scattering offset</span></strong>    <strong><span style="color: rgb(0, 113, 188);">float3</span></strong> v3Start = v3CameraPos + v3Ray * fNear;    fFar -= fNear;    <strong><span style="color: rgb(0, 113, 188);">float</span></strong> fStartAngle = <strong><span style="color: rgb(0, 113, 188);">dot</span></strong>(v3Ray, v3Start) / fOuterRadius;    <strong><span style="color: rgb(0, 113, 188);">float</span></strong> fStartDepth = <strong><span style="color: rgb(0, 113, 188);">exp</span></strong>(-fInvScaleDepth);    <strong><span style="color: rgb(0, 113, 188);">float</span></strong> fStartOffset = fStartDepth * <strong><span style="color: rgb(0, 113, 188);">scale</span></strong>(fStartAngle);      <strong><span style="color: rgb(156, 172, 59);">// Initialize the scattering loop variables</span></strong>      <strong><span style="color: rgb(0, 113, 188);">float</span></strong> fSampleLength = fFar / fSamples;    <strong><span style="color: rgb(0, 113, 188);">float</span></strong> fScaledLength = fSampleLength * fScale;    <strong><span style="color: rgb(0, 113, 188);">float3</span></strong> v3SampleRay = v3Ray * fSampleLength;    <strong><span style="color: rgb(0, 113, 188);">float3</span></strong> v3SamplePoint = v3Start + v3SampleRay * 0.5;      <strong><span style="color: rgb(156, 172, 59);">// Now loop through the sample points</span></strong>    <strong><span style="color: rgb(0, 113, 188);">float3</span></strong> v3FrontColor = <strong><span style="color: rgb(0, 113, 188);">float3</span></strong>(0.0, 0.0, 0.0);    <strong><span style="color: rgb(0, 113, 188);">for</span></strong>(<strong><span style="color: rgb(0, 113, 188);">int</span></strong> i=0; i&lt;nSamples; i++) {      <strong><span style="color: rgb(0, 113, 188);">float</span></strong> fHeight = <strong><span style="color: rgb(0, 113, 188);">length</span></strong>(v3SamplePoint);      <strong><span style="color: rgb(0, 113, 188);">float</span></strong> fDepth = <strong><span style="color: rgb(0, 113, 188);">exp</span></strong>(fScaleOverScaleDepth * (fInnerRadius - fHeight));      <strong><span style="color: rgb(0, 113, 188);">float</span></strong> fLightAngle = <strong><span style="color: rgb(0, 113, 188);">dot</span></strong>(v3LightDir, v3SamplePoint) / fHeight;      <strong><span style="color: rgb(0, 113, 188);">float</span></strong> fCameraAngle = <strong><span style="color: rgb(0, 113, 188);">dot</span></strong>(v3Ray, v3SamplePoint) / fHeight;      <strong><span style="color: rgb(0, 113, 188);">float</span></strong> fScatter = (fStartOffset + fDepth * (<strong><span style="color: rgb(0, 113, 188);">scale</span></strong>(fLightAngle) &#xD0;                                                <strong><span style="color: rgb(0, 113, 188);">scale</span></strong>(fCameraAngle)));      <strong><span style="color: rgb(0, 113, 188);">float3</span></strong> v3Attenuate = <strong><span style="color: rgb(0, 113, 188);">exp</span></strong>(-fScatter *                               (v3InvWavelength * fKr4PI + fKm4PI));      v3FrontColor += v3Attenuate * (fDepth * fScaledLength);      v3SamplePoint += v3SampleRay;    }      <strong><span style="color: rgb(156, 172, 59);">// Finally, scale the Mie and Rayleigh colors</span></strong>      <strong><span style="color: rgb(0, 113, 188);">vertout</span></strong> OUT;    OUT.pos = <strong><span style="color: rgb(0, 113, 188);">mul</span></strong>(gl_ModelViewProjectionMatrix, gl_Vertex);    OUT.c0.rgb = v3FrontColor * (v3InvWavelength * fKrESun);    OUT.c1.rgb = v3FrontColor * fKmESun;    OUT.t0 = v3CameraPos - v3Pos;    <strong><span style="color: rgb(0, 113, 188);">return</span></strong> OUT;  } </pre>        <h4>16.5.2 The Fragment Shader</h4>        <p>This shader should be fairly self-explanatory. One thing that is not shown in Listing 16-2 is that I commented out the math in the <tt>getRayleighPhase()</tt> function. The Rayleigh phase function causes the blue sky to be the brightest at       0 degrees and 180 degrees and the darkest at 90 degrees. However, I feel it makes the sky look too dark around 90 degrees. In theory, this problem arises because we are not implementing multiple scattering. Single scattering only calculates       how much light is scattered coming directly from the sun. Light that is scattered out of the path of a ray just vanishes. Multiple scattering attempts to figure out where that light went, and often it is redirected back toward the camera from       another angle. It is a lot like radiosity lighting, and it is not considered feasible to calculate in real time. Nishita et al. 1993 uses an ambient factor to brighten up the darker areas. I feel that it looks better to just leave out the       Rayleigh phase function entirely. Feel free to play with it and see what you like best.</p>        <h4>Example 16-2. SkyFromSpace.frag, Which Renders the Sky Dome When the Camera Is in Space</h4>       <pre> <strong><span style="color: rgb(0, 113, 188);">#include</span></strong> "Common.cg"    <strong><span style="color: rgb(0, 113, 188);">float4</span></strong> main(<strong><span style="color: rgb(0, 113, 188);">float4</span></strong> c0 : <strong><span style="color: rgb(0, 113, 188);">COLOR0</span></strong>,    <strong><span style="color: rgb(0, 113, 188);">float4</span></strong> c1 : <strong><span style="color: rgb(0, 113, 188);">COLOR1</span></strong>,    <strong><span style="color: rgb(0, 113, 188);">float3</span></strong> v3Direction : <strong><span style="color: rgb(0, 113, 188);">TEXCOORD0</span></strong>,    <strong><span style="color: rgb(0, 113, 188);">uniform</span></strong> <strong><span style="color: rgb(0, 113, 188);">float3</span></strong> v3LightDirection,    <strong><span style="color: rgb(0, 113, 188);">uniform</span></strong> <strong><span style="color: rgb(0, 113, 188);">float</span></strong> g,    <strong><span style="color: rgb(0, 113, 188);">uniform</span></strong> <strong><span style="color: rgb(0, 113, 188);">float</span></strong> g2) : <strong><span style="color: rgb(0, 113, 188);">COLOR</span></strong>    {    <strong><span style="color: rgb(0, 113, 188);">float</span></strong> fCos = <strong><span style="color: rgb(0, 113, 188);">dot</span></strong>(v3LightDirection, v3Direction) / <strong><span style="color: rgb(0, 113, 188);">length</span></strong>(v3Direction);    <strong><span style="color: rgb(0, 113, 188);">float</span></strong> fCos2 = fCos * fCos;    <strong><span style="color: rgb(0, 113, 188);">float4</span></strong> color = getRayleighPhase(fCos2) * c0 +                   getMiePhase(fCos, fCos2, g, g2) * c1;    color.a = color.b;    <strong><span style="color: rgb(0, 113, 188);">return</span></strong> color;  } </pre>        <h2>16.6 Adding High-Dynamic-Range Rendering</h2>        <p>Atmospheric scattering doesn't look very good without high-dynamic-range (HDR) rendering. This is because these equations can very easily generate images that are too bright or too dark. See Figure 16-4. It looks much better when you render       the image to a floating-point buffer and scale the colors to fall within the range 0..1 using an exponential curve with an adjustable exposure constant.</p>        <div class="figure" align="center">         <img src="/sites/all/modules/custom/gpugems/books/GPUGems2/elementLinks/16_atmospheric_04a.jpg" alt="16_atmospheric_04a.jpg" />          <p>Figure 16-4 The Importance of High Dynamic Range</p>       </div>        <p>The exposure equation used in this demo is very simple: 1.0 &#x2013; exp(-<em>fExposure</em> x <em>color</em>). The exposure constant works like the aperture of a camera or the pupils of your eyes. When there is too much light, the exposure       constant is reduced to let in less light. When there is not enough light, the exposure constant is increased to let in more light. Without reasonable limits set on the exposure constant, daylight can look like moonlight and vice versa.       Regardless, the relative brightness of each color is always preserved.</p>        <p>The HDR rendering implemented in this demo is also very simple. An OpenGL pbuffer is created with a floating-point pixel format and render-to-texture enabled. The same rendering code as before is used, but everything is rendered to the       pbuffer's rendering context. Afterward, the main rendering context is selected and a single quad is rendered to fill the screen. The floating-point buffer is selected as a texture, and a simple exponential scaling shader is used to scale the       colors to the normal 0&#x2013;255 range. The exposure constant is set manually and can be changed at runtime in the demo, along with several of the scattering constants used.</p>        <p>Fortunately, modern GPUs support floating-point render targets. Some critical features such as alpha blending aren't available until you move up to GeForce 6 Series GPUs, so blending the sky dome with objects rendered in space won't work       for older GPUs.</p>        <h2>16.7 Conclusion</h2>        <p>Although it took a fair number of simplifications to be able to interactively render scenes with the model described, the demo looks pretty sharp, especially with HDR rendering. Tweaking the parameters to the system can be a source of much       entertainment; I had never imagined that the sky at the horizon would be orange at high noon if our atmosphere were a little thicker, or that sunsets would look that much more incredible. Red and orange skies produce sunsets of different       shades of blue, and purple skies produce green sunsets. Once I even managed to find settings that produced a rainbow sunset.</p>        <p>In any case, the work is not done here. There are a number of improvements that could be made to this algorithm:</p>        <ol>         <li>Create an atmospheric-density scale function that is not hard-coded to a specific scale height and the ratio between the atmosphere thickness and the planetary radius.</li>          <li>Split up the Rayleigh and Mie scattering so that they can have different scale depths.</li>          <li>Provide a better way to simulate multiple scattering and start using the Rayleigh phase function again.</li>          <li>Allow light from other sources, such as the moon, to be scattered, as well as sunlight. This would be necessary to create a moonlight effect with a halo surrounding the moon.</li>          <li>Atmospheric scattering also makes distant objects look larger and blurrier than they are. The moon would look much smaller to us if it were not viewed through an atmosphere. It may be possible to achieve this in the HDR pass with some         sort of blurring filter that is based on optical depth.</li>          <li>Change the sample points taken along the ray from linear to exponential based on altitude. Nishita et al. 1993 explains why this is beneficial.</li>          <li>Add other atmospheric effects, such as clouds, precipitation, lightning, and rainbows. See Harris 2001, Brewer 2004, and Dobashi et al. 2001.</li>       </ol>        <h2>16.8 References</h2>        <p><a name="biblio16_01" id="biblio16_01"></a>Brewer, Clint. 2004. "Rainbows and Fogbows: Adding Natural Phenomena." NVIDIA Corporation. SDK white paper. <strong><a href="http://download.nvidia.com/developer/SDK/Individual_Samples/DEMOS/Direct3D9/src/HLSL_RainbowFogbow/docs/RainbowFogbow.pdf">http://download.nvidia.com/developer/SDK/Individual_Samples/DEMOS/Direct3D9/src/HLSL_RainbowFogbow/docs/RainbowFogbow.pdf</a></strong></p>        <p><a name="biblio16_02" id="biblio16_02"></a>Dobashi, Y., T. Yamamoto, and T. Nishita. 2001. "Efficient Rendering of Lightning Taking into Account Scattering Effects due to Clouds and Atmospheric Particles." <strong><a href="http://nis-lab.is.s.u-tokyo.ac.jp/~nis/cdrom/pg/pg01_lightning.pdf">http://nis-lab.is.s.u-tokyo.ac.jp/~nis/cdrom/pg/pg01_lightning.pdf</a></strong></p>        <p><a name="biblio16_03" id="biblio16_03"></a>Harris, Mark J., and Anselmo Lastra. 2001. "Real-Time Cloud Rendering." <em>Eurographics 2001</em> 20(3), pp. 76&#x2013;84. <strong><a href="http://www.markmark.net/PDFs/RTClouds_HarrisEG2001.pdf">http://www.markmark.net/PDFs/RTClouds_HarrisEG2001.pdf</a></strong></p>        <p><a name="biblio16_04" id="biblio16_04"></a>Hoffman, N., and A. J. Preetham. 2002. "Rendering Outdoor Scattering in Real Time." ATI Corporation. <strong><a href="http://www.ati.com/developer/dx9/ATI-LightScattering.pdf">http://www.ati.com/developer/dx9/ATI-LightScattering.pdf</a></strong></p>        <p><a name="biblio16_05" id="biblio16_05"></a>Nishita, T., T. Sirai, K. Tadamura, and E. Nakamae. 1993. "Display of the Earth Taking into Account Atmospheric Scattering." In <em>Proceedings of SIGGRAPH 93</em>, pp. 175&#x2013;182.       <strong><a href="http://nis-lab.is.s.u-tokyo.ac.jp/~nis/cdrom/sig93_nis.pdf">http://nis-lab.is.s.u-tokyo.ac.jp/~nis/cdrom/sig93_nis.pdf</a></strong></p>        <p><a name="biblio16_06" id="biblio16_06"></a>O'Neil, Sean. 2004. "Real-Time Atmospheric Scattering." GameDev.net. <strong><a href="http://www.gamedev.net/columns/hardcore/atmscattering/">http://www.gamedev.net/columns/hardcore/atmscattering/</a></strong></p>  <!-- generated html end -->        <!-- Copyright info for The Cg Tutorial -->       <hr />        <h4>Copyright</h4>        <p>Many of the designations used by manufacturers and sellers to distinguish their products are claimed as trademarks. Where those designations appear in this book, and Addison-Wesley was aware of a trademark claim, the designations have been       printed with initial capital letters or in all capitals.</p>        <p>The authors and publisher have taken care in the preparation of this book, but make no expressed or implied warranty of any kind and assume no responsibility for errors or omissions. No liability is assumed for incidental or consequential       damages in connection with or arising out of the use of the information or programs contained herein.</p>        <p>NVIDIA makes no warranty or representation that the techniques described herein are free from any Intellectual Property claims. The reader assumes all risk of any such claims based on his or her use of these techniques.</p>        <p>The publisher offers excellent discounts on this book when ordered in quantity for bulk purchases or special sales, which may include electronic versions and/or custom covers and content particular to your business, training goals,       marketing focus, and branding interests. For more information, please contact:</p>        <p>&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;U.S.&#xA0;Corporate&#xA0;and&#xA0;Government&#xA0;Sales<br />       &#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;(800)&#xA0;382-3419<br />       &#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;<a href="mailto:corpsales@pearsontechgroup.com">corpsales@pearsontechgroup.com</a></p>        <p>For sales outside of the U.S., please contact:</p>        <p>&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;International&#xA0;Sales<br />       &#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;<a href="mailto:international@pearsoned.com">international@pearsoned.com</a></p>        <p>Visit Addison-Wesley on the Web: <a href="http://www.awprofessional.com">www.awprofessional.com</a></p>        <p><em>Library of Congress Cataloging-in-Publication Data</em></p>        <p>GPU&#xA0;gems&#xA0;2&#xA0;:&#xA0;programming&#xA0;techniques&#xA0;for&#xA0;high-performance&#xA0;graphics&#xA0;and&#xA0;general-purpose<br />       computation&#xA0;/&#xA0;edited&#xA0;by&#xA0;Matt&#xA0;Pharr&#xA0;;&#xA0;Randima&#xA0;Fernando,&#xA0;series&#xA0;editor.<br />       &#xA0;&#xA0;&#xA0;&#xA0;p.&#xA0;cm.<br />       &#xA0;&#xA0;Includes&#xA0;bibliographical&#xA0;references&#xA0;and&#xA0;index.<br />       &#xA0;&#xA0;ISBN&#xA0;0-321-33559-7&#xA0;(hardcover&#xA0;:&#xA0;alk.&#xA0;paper)<br />       &#xA0;&#xA0;1.&#xA0;Computer&#xA0;graphics.&#xA0;2.&#xA0;Real-time&#xA0;programming.&#xA0;I.&#xA0;Pharr,&#xA0;Matt.&#xA0;II.&#xA0;Fernando,&#xA0;Randima.<br />       <br />       &#xA0;&#xA0;T385.G688&#xA0;2005<br />       &#xA0;&#xA0;006.66&#x2014;dc22<br />       &#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;2004030181</p>        <p>GeForce&#x2122; and NVIDIA Quadro&#xAE; are trademarks or registered trademarks of NVIDIA Corporation.</p>        <p>Nalu, Timbury, and Clear Sailing images &#xA9; 2004 NVIDIA Corporation.</p>        <p>mental images and mental ray are trademarks or registered trademarks of mental images, GmbH.</p>        <p>Copyright &#xA9; 2005 by NVIDIA Corporation.</p>        <p>All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted, in any form, or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior consent of the       publisher. Printed in the United States of America. Published simultaneously in Canada.</p>        <p>For information on obtaining permission for use of material from this work, please submit a written request to:</p>        <p>&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;Pearson&#xA0;Education,&#xA0;Inc.<br />       &#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;Rights&#xA0;and&#xA0;Contracts&#xA0;Department<br />       &#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;One&#xA0;Lake&#xA0;Street<br />       &#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;Upper&#xA0;Saddle&#xA0;River,&#xA0;NJ&#xA0;07458</p>        <p>Text printed in the United States on recycled paper at Quebecor World Taunton in Taunton, Massachusetts.</p>        <p>Second printing, April 2005</p>        <h2>Dedication</h2>        <blockquote>         <p><em>To everyone striving to make today's best computer graphics look primitive tomorrow</em></p>       </blockquote> <!-- <div align="right" style=" color:#999999;">Last Update: 09:24 09/22/2008</div> -->    </div>
    <div class="col-md-4">
      <ul><li><a href="/gpugems/gpugems2/copyright" class="">Copyright</a></li>
<li><a href="/gpugems/gpugems2/inside-back-cover" class="">Inside Back Cover</a></li>
<li><a href="/gpugems/gpugems2/inside-front-cover" class="">Inside Front Cover</a></li>
<li><a href="/gpugems/gpugems2/part-i-geometric-complexity" class="">Part I: Geometric Complexity</a><ul><li><a href="/gpugems/gpugems2/part-i-geometric-complexity/chapter-1-toward-photorealism-virtual-botany" class="">Chapter 1. Toward Photorealism in Virtual Botany</a></li>
<li><a href="/gpugems/gpugems2/part-i-geometric-complexity/chapter-2-terrain-rendering-using-gpu-based-geometry" class="">Chapter 2. Terrain Rendering Using GPU-Based Geometry Clipmaps</a></li>
<li><a href="/gpugems/gpugems2/part-i-geometric-complexity/chapter-3-inside-geometry-instancing" class="">Chapter 3. Inside Geometry Instancing</a></li>
<li><a href="/gpugems/gpugems2/part-i-geometric-complexity/chapter-4-segment-buffering" class="">Chapter 4. Segment Buffering</a></li>
<li><a href="/gpugems/gpugems2/part-i-geometric-complexity/chapter-5-optimizing-resource-management-multistreaming" class="">Chapter 5. Optimizing Resource Management with Multistreaming</a></li>
<li><a href="/gpugems/gpugems2/part-i-geometric-complexity/chapter-6-hardware-occlusion-queries-made-useful" class="">Chapter 6. Hardware Occlusion Queries Made Useful</a></li>
<li><a href="/gpugems/gpugems2/part-i-geometric-complexity/chapter-7-adaptive-tessellation-subdivision-surfaces" class="">Chapter 7. Adaptive Tessellation of Subdivision Surfaces with Displacement Mapping</a></li>
<li><a href="/gpugems/gpugems2/part-i-geometric-complexity/chapter-8-pixel-displacement-mapping-distance-functions" class="">Chapter 8. Per-Pixel Displacement Mapping with Distance Functions</a></li>
</ul></li>
<li><a href="/gpugems/gpugems2/part-ii-shading-lighting-and-shadows" class="active">Part II: Shading, Lighting, and Shadows</a><ul><li><a href="/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-10-real-time-computation-dynamic" class="">Chapter 10. Real-Time Computation of Dynamic Irradiance Environment Maps</a></li>
<li><a href="/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-11-approximate-bidirectional-texture" class="">Chapter 11. Approximate Bidirectional Texture Functions</a></li>
<li><a href="/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-12-tile-based-texture-mapping" class="">Chapter 12. Tile-Based Texture Mapping</a></li>
<li><a href="/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-13-implementing-mental-images" class="">Chapter 13. Implementing the mental images Phenomena Renderer on the GPU</a></li>
<li><a href="/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-14-dynamic-ambient-occlusion-and" class="">Chapter 14. Dynamic Ambient Occlusion and Indirect Lighting</a></li>
<li><a href="/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-15-blueprint-rendering-and-sketchy" class="">Chapter 15. Blueprint Rendering and &quot;Sketchy Drawings&quot;</a></li>
<li><a href="/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-16-accurate-atmospheric-scattering" class="active">Chapter 16. Accurate Atmospheric Scattering</a></li>
<li><a href="/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-17-efficient-soft-edged-shadows-using" class="">Chapter 17. Efficient Soft-Edged Shadows Using Pixel Shader Branching</a></li>
<li><a href="/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-18-using-vertex-texture-displacement" class="">Chapter 18. Using Vertex Texture Displacement for Realistic Water Rendering</a></li>
<li><a href="/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-19-generic-refraction-simulation" class="">Chapter 19. Generic Refraction Simulation</a></li>
<li><a href="/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-9-deferred-shading-stalker" class="">Chapter 9. Deferred Shading in S.T.A.L.K.E.R.</a></li>
</ul></li>
<li><a href="/gpugems/gpugems2/part-iii-high-quality-rendering" class="">Part III: High-Quality Rendering</a><ul><li><a href="/gpugems/gpugems2/part-iii-high-quality-rendering/chapter-20-fast-third-order-texture-filtering" class="">Chapter 20. Fast Third-Order Texture Filtering</a></li>
<li><a href="/gpugems/gpugems2/part-iii-high-quality-rendering/chapter-21-high-quality-antialiased-rasterization" class="">Chapter 21. High-Quality Antialiased Rasterization</a></li>
<li><a href="/gpugems/gpugems2/part-iii-high-quality-rendering/chapter-22-fast-prefiltered-lines" class="">Chapter 22. Fast Prefiltered Lines</a></li>
<li><a href="/gpugems/gpugems2/part-iii-high-quality-rendering/chapter-23-hair-animation-and-rendering-nalu-demo" class="">Chapter 23. Hair Animation and Rendering in the Nalu Demo</a></li>
<li><a href="/gpugems/gpugems2/part-iii-high-quality-rendering/chapter-24-using-lookup-tables-accelerate-color" class="">Chapter 24. Using Lookup Tables to Accelerate Color Transformations</a></li>
<li><a href="/gpugems/gpugems2/part-iii-high-quality-rendering/chapter-25-gpu-image-processing-apples-motion" class="">Chapter 25. GPU Image Processing in Apple&#039;s Motion</a></li>
<li><a href="/gpugems/gpugems2/part-iii-high-quality-rendering/chapter-26-implementing-improved-perlin-noise" class="">Chapter 26. Implementing Improved Perlin Noise</a></li>
<li><a href="/gpugems/gpugems2/part-iii-high-quality-rendering/chapter-27-advanced-high-quality-filtering" class="">Chapter 27. Advanced High-Quality Filtering</a></li>
<li><a href="/gpugems/gpugems2/part-iii-high-quality-rendering/chapter-28-mipmap-level-measurement" class="">Chapter 28. Mipmap-Level Measurement</a></li>
</ul></li>
<li><a href="/gpugems/gpugems2/part-iv-general-purpose-computation-gpus-primer" class="">Part IV: General-Purpose Computation on GPUS: A Primer</a><ul><li><a href="/gpugems/gpugems2/part-iv-general-purpose-computation-gpus-primer/chapter-29-streaming-architectures" class="">Chapter 29. Streaming Architectures and Technology Trends</a></li>
<li><a href="/gpugems/gpugems2/part-iv-general-purpose-computation-gpus-primer/chapter-30-geforce-6-series-gpu" class="">Chapter 30. The GeForce 6 Series GPU Architecture</a></li>
<li><a href="/gpugems/gpugems2/part-iv-general-purpose-computation-gpus-primer/chapter-31-mapping-computational" class="">Chapter 31. Mapping Computational Concepts to GPUs</a></li>
<li><a href="/gpugems/gpugems2/part-iv-general-purpose-computation-gpus-primer/chapter-32-taking-plunge-gpu" class="">Chapter 32. Taking the Plunge into GPU Computing</a></li>
<li><a href="/gpugems/gpugems2/part-iv-general-purpose-computation-gpus-primer/chapter-33-implementing-efficient" class="">Chapter 33. Implementing Efficient Parallel Data Structures on GPUs</a></li>
<li><a href="/gpugems/gpugems2/part-iv-general-purpose-computation-gpus-primer/chapter-34-gpu-flow-control-idioms" class="">Chapter 34. GPU Flow-Control Idioms</a></li>
<li><a href="/gpugems/gpugems2/part-iv-general-purpose-computation-gpus-primer/chapter-35-gpu-program-optimization" class="">Chapter 35. GPU Program Optimization</a></li>
<li><a href="/gpugems/gpugems2/part-iv-general-purpose-computation-gpus-primer/chapter-36-stream-reduction" class="">Chapter 36. Stream Reduction Operations for GPGPU Applications</a></li>
</ul></li>
<li><a href="/gpugems/gpugems2/part-v-image-oriented-computing" class="">Part V: Image-Oriented Computing</a><ul><li><a href="/gpugems/gpugems2/part-v-image-oriented-computing/chapter-37-octree-textures-gpu" class="">Chapter 37. Octree Textures on the GPU</a></li>
<li><a href="/gpugems/gpugems2/part-v-image-oriented-computing/chapter-38-high-quality-global-illumination" class="">Chapter 38. High-Quality Global Illumination Rendering Using Rasterization</a></li>
<li><a href="/gpugems/gpugems2/part-v-image-oriented-computing/chapter-39-global-illumination-using-progressive" class="">Chapter 39. Global Illumination Using Progressive Refinement Radiosity</a></li>
<li><a href="/gpugems/gpugems2/part-v-image-oriented-computing/chapter-40-computer-vision-gpu" class="">Chapter 40. Computer Vision on the GPU</a></li>
<li><a href="/gpugems/gpugems2/part-v-image-oriented-computing/chapter-41-deferred-filtering-rendering-difficult" class="">Chapter 41. Deferred Filtering: Rendering from Difficult Data Formats</a></li>
<li><a href="/gpugems/gpugems2/part-v-image-oriented-computing/chapter-42-conservative-rasterization" class="">Chapter 42. Conservative Rasterization</a></li>
</ul></li>
<li><a href="/gpugems/gpugems2/part-vi-simulation-and-numerical-algorithms" class="">Part VI: Simulation and Numerical Algorithms</a><ul><li><a href="/gpugems/gpugems2/part-vi-simulation-and-numerical-algorithms/chapter-43-gpu-computing-protein" class="">Chapter 43. GPU Computing for Protein Structure Prediction</a></li>
<li><a href="/gpugems/gpugems2/part-vi-simulation-and-numerical-algorithms/chapter-44-gpu-framework-solving" class="">Chapter 44. A GPU Framework for Solving Systems of Linear Equations</a></li>
<li><a href="/gpugems/gpugems2/part-vi-simulation-and-numerical-algorithms/chapter-45-options-pricing-gpu" class="">Chapter 45. Options Pricing on the GPU</a></li>
<li><a href="/gpugems/gpugems2/part-vi-simulation-and-numerical-algorithms/chapter-46-improved-gpu-sorting" class="">Chapter 46. Improved GPU Sorting</a></li>
<li><a href="/gpugems/gpugems2/part-vi-simulation-and-numerical-algorithms/chapter-47-flow-simulation-complex" class="">Chapter 47. Flow Simulation with Complex Boundaries</a></li>
<li><a href="/gpugems/gpugems2/part-vi-simulation-and-numerical-algorithms/chapter-48-medical-image-reconstruction" class="">Chapter 48. Medical Image Reconstruction with the FFT</a></li>
</ul></li>
</ul>    </div>
  </div>
</div>
</div>
</section>
<<<<<<< HEAD
  </div>
=======
  </div>
>>>>>>> 17e2c9f0015b84508c0980fb762a587738dc55ae
                  </section>

        
      </div>
    </div>
    <div class="separator"></div>
  </div>
  
      <footer>
      <div class="footer-links">
        <div class="container">
          <div class="row">
            <div class="col-xs-12 col-sm-12 col-md-3 col-lg-3">
              <div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">
                <div class="padding-md-footer">
                  <div class="logo-footer"></div>
                </div>
              </div>
              <div
                class="col-xs-12 col-sm-12 col-md-9 col-lg-9 padding-section-footer">
<<<<<<< HEAD
                  <div class="region region-footer-menu">
=======
                  <div class="region region-footer-menu">
>>>>>>> 17e2c9f0015b84508c0980fb762a587738dc55ae
    <div class="block block-menu" id="block-menu-menu-footer-menu">
  <div class="block-content zone-select">
    <ul class="menu nav"><li class="first leaf"><a href="/hpc" title="">HIGH PERFORMANCE COMPUTING</a></li>
<li class="leaf"><a href="/gameworks" title="">GAMEWORKS</a></li>
<li class="leaf"><a href="/embedded-computing" title="">JETPACK</a></li>
<li class="leaf"><a href="/designworks" title="">DESIGNWORKS</a></li>
<li class="last leaf"><a href="/drive" title="">DRIVE</a></li>
</ul>  </div>
</div>
<<<<<<< HEAD
  </div>
=======
  </div>
>>>>>>> 17e2c9f0015b84508c0980fb762a587738dc55ae
              </div>
            </div>
            <div class="col-xs-12 col-sm-12 col-md-9 col-lg-9">
                                                        </div>
          </div>
        </div>
      </div>

      <div class="footer-boilerplate">
        <div class="container">
          <div class="boilerplate">
            <div class="col-xs-12 col-sm-12 col-lg-9 padding-sm-bottom">
              Copyright &copy; 2020 NVIDIA Corporation                              <ul class="legal_links" ><li class="first leaf"><a href="https://www.nvidia.com/en-us/about-nvidia/legal-info/" title="">Legal Information</a></li>
<li class="leaf"><a href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/" title="">Privacy Policy</a></li>
<li class="leaf"><a href="/contact" title="">Contact</a></li>
<li class="last leaf"><a href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/" title="NVIDIA websites use cookies to deliver and improve the website experience. See our cookie policy for further details on how we use cookies and how to change your cookie settings.">Cookie policy</a></li>
</ul>                          </div>
          </div>
        </div>
      </div>
    </footer>
  </div>
  <script>var dzauth = {"settings":{"client_id":"4jljTejN7RMO9suL0S33gFrYgjHX0VcW","redirect_uri":"https:\/\/developer.nvidia.com\/auth0\/callback","custom_domain":"login.developer.nvidia.com","domain":"devzone.auth0.com","auto_login":true}};

function nvidia_dzauth_register_and_redirect(redirect_destination) {
  if(redirect_destination) {
    history.pushState(null, '', redirect_destination);
    showDzAuth('login');
  }
}

function nvidia_dzauth_init() {
  initDzAuth(dzauth);
  if (typeof auth0 !== 'undefined') {
    dzCheckSession(auth0);
  }
}
nvidia_dzauth_init();
</script>
<script>_satellite.pageBottom();</script>
<script src="https://developer.nvidia.com/sites/default/files/js/js_A9Fkq5INW56iszcGnz5c1_qnhJAq0-boELbnJIZ40KQ.js"></script>
<script type="text/javascript">window.NREUM||(NREUM={});NREUM.info={"beacon":"bam.nr-data.net","licenseKey":"6f2048d7bc","applicationID":"341156206","transactionName":"YFVbbEJQXhJTW0JRX1kfeFtEWF8PHUxXQF9ZX1RBb1VZEkJUV0FvQ1FBV15eXRhtTFNKXWhAWF9V","queueTime":0,"applicationTime":327,"atts":"TBJYGgpKTRw=","errorBeacon":"bam.nr-data.net","agent":""}</script></body>
</html>
